{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53abd3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torchaudio\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#set random seeds for reproducibility\n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "repo_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(repo_root / \"src\"))\n",
    "\n",
    "model_path = repo_root / 'models' / 'GRU_VAD' /'tiny_vad_best.pth'\n",
    "\n",
    "from utils.audio_dataset_loader import (\n",
    "    load_ears_dataset,\n",
    "    load_noizeus_dataset,\n",
    "    create_audio_pairs,\n",
    "    preprocess_audio\n",
    ")\n",
    "from utils.generate_and_save_spectrogram import generate_and_save_spectrogram\n",
    "from utils.compute_and_save_speech_metrics import compute_and_save_speech_metrics\n",
    "from utils.parse_and_merge_csvs import merge_csvs\n",
    "from utils.delete_csvs import delete_csvs_in_directory as delete_csvs\n",
    "from dsp_algorithms.wiener_as import wiener_filter\n",
    "from dsp_algorithms.wiener_GTCRN import wiener_filter as wiener_gtcrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f82fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test datasets\n",
    "print(\"Loading EARS test dataset...\")\n",
    "ears_files = load_ears_dataset(repo_root, mode=\"test\")\n",
    "print(f\"Loaded {len(ears_files)} EARS files for test mode\")\n",
    "\n",
    "print(\"Loading NOIZEUS test dataset...\")\n",
    "noizeus_files = load_noizeus_dataset(repo_root)\n",
    "print(f\"Loaded {len(noizeus_files)} NOIZEUS files for test mode\")\n",
    "\n",
    "# Create audio pairs\n",
    "paired_files = create_audio_pairs(noizeus_files, ears_files)\n",
    "print(f\"Created {len(paired_files)} audio pairs for processing\")\n",
    "\n",
    "noise_path, clean_path = paired_files[16]\n",
    "\n",
    "snr_dB = 0\n",
    "\n",
    "clean_waveform, noise_waveform, noisy_speech, clean_sr = preprocess_audio(\n",
    "    clean_speech=clean_path, \n",
    "    noisy_audio=noise_path, \n",
    "    snr_db=snr_dB\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e14c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n2. Applying causal Wiener filtering...\")\n",
    "threshold = 0.5  # VAD decision threshold\n",
    "enhanced_speech_wf_gru_vad, enhanced_fs = wiener_filter(\n",
    "    noisy_audio=noisy_speech,\n",
    "    fs=16000,\n",
    "    frame_dur_ms=8\n",
    "    #output_dir=output_dir_snr,\n",
    "    #output_file=output_filename.replace('.wav', ''),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ffba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n2. Applying causal Wiener filtering...\")\n",
    "enhanced_speech_as, enhanced_fs = wiener_filter(\n",
    "    noisy_audio=noisy_speech,\n",
    "    fs=16000,\n",
    "    mu=0.98,\n",
    "    a_dd=0.98,\n",
    "    eta=0.15,\n",
    "    frame_dur_ms=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f83936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SIDE-BY-SIDE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare audio signals for comparison\n",
    "noisy_compare = noisy_speech.clone().squeeze(0)\n",
    "wf_as_compare = enhanced_speech_as.clone().squeeze(0)\n",
    "enhanced_output = enhanced_speech_wf_gru_vad.clone().squeeze(0)\n",
    "wf_gru_compare = enhanced_speech_wf_gru_vad.clone().squeeze(0)\n",
    "clean_compare = clean_waveform.clone().squeeze(0)\n",
    "\n",
    "fs = 16000\n",
    "\n",
    "print(f\"\\nAudio lengths before trimming:\")\n",
    "print(f\"  noisy:              {len(noisy_compare)}\")\n",
    "print(f\"  WF as:              {len(wf_as_compare)}\")\n",
    "print(f\"  WF TinyGRU (thr=0.05): {len(wf_gru_compare)}\")\n",
    "print(f\"  clean:              {len(clean_compare)}\")\n",
    "\n",
    "# Trim to shortest length\n",
    "min_len = min(\n",
    "    len(noisy_compare), \n",
    "    len(wf_as_compare),\n",
    "    len(wf_gru_compare),\n",
    "    len(clean_compare)\n",
    ")\n",
    "\n",
    "noisy_compare = noisy_compare[:min_len]\n",
    "wf_as_compare = wf_as_compare[:min_len]\n",
    "wf_gru_compare = wf_gru_compare[:min_len]\n",
    "clean_compare = clean_compare[:min_len]\n",
    "\n",
    "print(f\"\\nTrimmed to: {min_len} samples ({min_len/fs:.2f}s)\")\n",
    "\n",
    "# Create 4-panel comparison plot\n",
    "fig, axes = plt.subplots(4, 1, figsize=(16, 12))\n",
    "time_axis = np.arange(min_len) / fs\n",
    "\n",
    "# 1. Noisy\n",
    "axes[0].plot(time_axis, noisy_compare.numpy(), 'r', alpha=0.7, linewidth=0.8)\n",
    "axes[0].set_title(f'1. Noisy Speech (SNR = {snr_dB}dB)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xlim(0, min_len/fs)\n",
    "\n",
    "# 2. Wiener AS\n",
    "axes[1].plot(time_axis, wf_as_compare.numpy(), 'orange', alpha=0.7, linewidth=0.8)\n",
    "axes[1].set_title('2. Wiener Filter (AS method)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Amplitude')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xlim(0, min_len/fs)\n",
    "\n",
    "# 3. Wiener + TinyGRU VAD\n",
    "axes[2].plot(time_axis, wf_gru_compare.numpy(), 'b', alpha=0.7, linewidth=0.8)\n",
    "axes[2].set_title('3. Wiener + TinyGRU VAD (threshold=0.5)', fontsize=12, fontweight='bold')\n",
    "axes[2].set_ylabel('Amplitude')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "axes[2].set_xlim(0, min_len/fs)\n",
    "\n",
    "# 4. Clean reference\n",
    "axes[3].plot(time_axis, clean_compare.numpy(), 'g', alpha=0.7, linewidth=0.8)\n",
    "axes[3].set_title('4. Clean Speech (Reference)', fontsize=12, fontweight='bold')\n",
    "axes[3].set_ylabel('Amplitude')\n",
    "axes[3].set_xlabel('Time (s)')\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "axes[3].set_xlim(0, min_len/fs)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Audio playback comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AUDIO PLAYBACK COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"NOISY SPEECH (0dB SNR):\")\n",
    "display(ipd.Audio(noisy_compare.numpy(), rate=fs))\n",
    "\n",
    "print(\"\\nWIENER FILTER (AS method):\")\n",
    "display(ipd.Audio(wf_as_compare.numpy(), rate=fs))\n",
    "\n",
    "print(\"\\nWIENER + TinyGRUVAD (threshold=0.5):\")\n",
    "display(ipd.Audio(wf_gru_compare.numpy(), rate=fs))\n",
    "\n",
    "print(\"\\nCLEAN SPEECH (Reference):\")\n",
    "display(ipd.Audio(clean_compare.numpy(), rate=fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7c40f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "from dsp_algorithms.wiener_GTCRN import wiener_filter as wiener_gtcrn\n",
    "\n",
    "# Use the audio waveforms from earlier\n",
    "noisy_waveform = noisy_speech.squeeze(0)\n",
    "clean_waveform_trimmed = clean_waveform.squeeze(0)[:len(noisy_waveform)]\n",
    "sample_rate = 16000\n",
    "\n",
    "# Apply Wiener filter to noisy\n",
    "print(\"Applying Wiener GTCRN filter...\")\n",
    "enhanced_audio, _ = wiener_gtcrn(noisy_waveform, sample_rate)\n",
    "\n",
    "# Generate and save spectrograms using the utility function\n",
    "print(\"Generating and saving spectrograms...\")\n",
    "filter_type = \"wiener_gtcrn\"\n",
    "output_path = f\"spectrograms/{filter_type}\"\n",
    "\n",
    "generate_and_save_spectrogram(\n",
    "    waveform=noisy_waveform,\n",
    "    sample_rate=sample_rate,\n",
    "    output_image_path=output_path,\n",
    "    output_file_name=\"noisy_spectrogram\",\n",
    "    title=\"Noise Mel Spectrogram\",\n",
    "    n_mels=128,\n",
    "    hop_length=512,\n",
    "    n_fft=1024,\n",
    "    colormap='plasma',\n",
    "    include_metadata_in_filename=False\n",
    ")\n",
    "\n",
    "ipd.display(ipd.Image(filename=f'{output_path}/noisy_spectrogram.png'))\n",
    "\n",
    "generate_and_save_spectrogram(\n",
    "    waveform=clean_waveform_trimmed,\n",
    "    sample_rate=sample_rate,\n",
    "    output_image_path=output_path,\n",
    "    output_file_name=\"clean_spectrogram\",\n",
    "    title=\"Clean Speech Mel Spectrogram\",\n",
    "    n_mels=128,\n",
    "    hop_length=512,\n",
    "    n_fft=1024,\n",
    "    colormap='plasma',\n",
    "    include_metadata_in_filename=False\n",
    ")\n",
    "\n",
    "ipd.display(ipd.Image(filename=f'{output_path}/clean_spectrogram.png'))\n",
    "\n",
    "generate_and_save_spectrogram(\n",
    "    waveform=enhanced_audio,\n",
    "    sample_rate=sample_rate,\n",
    "    output_image_path=output_path,\n",
    "    output_file_name=\"enhanced_spectrogram\",\n",
    "    title=\"Enhanced Speech Mel Spectrogram (Wiener GTCRN)\",\n",
    "    n_mels=128,\n",
    "    hop_length=512,\n",
    "    n_fft=1024,\n",
    "    colormap='plasma',\n",
    "    include_metadata_in_filename=False\n",
    ")\n",
    "\n",
    "ipd.display(ipd.Image(filename=f'{output_path}/enhanced_spectrogram.png'))\n",
    "\n",
    "print(\"Spectrograms generated, saved, and displayed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
