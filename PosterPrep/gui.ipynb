{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3410c69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "‚úì Models loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"background: linear-gradient(135deg, #1976D2 0%, #1565C0 100%); \n",
       "            padding: 40px; border-radius: 16px; margin-bottom: 30px; \n",
       "            box-shadow: 0 8px 32px rgba(25, 118, 210, 0.3);\">\n",
       "    <h1 style=\"margin: 0; font-size: 2.5em; color: white; font-weight: 600; letter-spacing: -0.5px;\">\n",
       "        üéµ Speech Enhancement System\n",
       "    </h1>\n",
       "    <p style=\"margin: 12px 0 0 0; font-size: 1.15em; color: rgba(255,255,255,0.95); font-weight: 400;\">\n",
       "        Advanced Audio Processing with Deep Learning & DSP Algorithms\n",
       "    </p>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"margin: 25px 0 15px 0;\">\n",
       "    <h2 style=\"color: #424242; font-weight: 600; font-size: 1.3em; margin: 0;\">\n",
       "        üìÅ Input Selection\n",
       "    </h2>\n",
       "    <div style=\"height: 3px; width: 50px; background: linear-gradient(90deg, #1976D2, #64B5F6); \n",
       "                border-radius: 2px; margin-top: 8px;\"></div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73f0b9334d34ffa8d0c9ac64b5c7cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Upload your own noisy audio file', indent=False, layout=Layout(width='500px‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c058974f7f647e996c51fc9784b5caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.wav,.mp3', description='Select Audio File', layout=Layout(width='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7ca40be88846958843bcfa337ee154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"margin: 30px 0 15px 0;\">\n",
       "    <h2 style=\"color: #424242; font-weight: 600; font-size: 1.3em; margin: 0;\">\n",
       "        üéõÔ∏è Audio Configuration\n",
       "    </h2>\n",
       "    <div style=\"height: 3px; width: 50px; background: linear-gradient(90deg, #1976D2, #64B5F6); \n",
       "                border-radius: 2px; margin-top: 8px;\"></div>\n",
       "    <p style=\"color: #757575; margin: 10px 0 15px 0; font-size: 0.95em;\">\n",
       "        Configure noise and speech settings (used when not uploading a file)\n",
       "    </p>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af5055cea19479c8a17243eecd9346a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Noise Type:', index=1, layout=Layout(width='500px'), options=('Cafeteria Babble', 'Stree‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7f86c4258d4cf2ad77899840c8c2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Speech Emotion:', layout=Layout(width='500px'), options=('Amazement', 'Anger', 'Disgust'‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a26953c6ed4dd586a8e53a77ddac9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, continuous_update=False, description='SNR Level (dB):', layout=Layout(width='500px'), max=2‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<p style=\"color: #757575; font-size: 0.9em; margin: 5px 0 0 165px; line-height: 1.5;\">\n",
       "    <strong>Lower values:</strong> More challenging noise conditions<br>\n",
       "    <strong>Higher values:</strong> Cleaner signal with less noise\n",
       "</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin: 30px 0 20px 0;\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e6657781aa44c794fde1adc7783603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='üéõÔ∏è  Process Audio', layout=Layout(height='56px', width='500px'), style=ButtonStyle(button_‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e4e57958df4470b17c94e22e800bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"background: linear-gradient(135deg, #E3F2FD 0%, #BBDEFB 100%); \n",
       "            padding: 20px; border-left: 4px solid #1976D2; \n",
       "            border-radius: 12px; margin-top: 30px; box-shadow: 0 2px 8px rgba(0,0,0,0.06);\">\n",
       "    <div style=\"color: #1565C0; line-height: 1.8;\">\n",
       "        <div style=\"font-weight: 600; font-size: 1.1em; margin-bottom: 10px;\">üí° Usage Instructions</div>\n",
       "        <div style=\"font-size: 0.95em;\">\n",
       "            <strong>1.</strong> Choose input method: Upload your noisy audio OR use predefined settings<br>\n",
       "            <strong>2.</strong> Click \"Process Audio\" and wait 10-30 seconds for processing<br>\n",
       "            <strong>3.</strong> Compare the enhancement techniques in waveforms and audio playback<br>\n",
       "            <strong>4.</strong> GTCRN + MBAND and GTCRN + Wiener offer state-of-the-art noise reduction\n",
       "        </div>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torchaudio\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, Layout, VBox, HBox, Button, HTML as HTMLWidget\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import io\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Setup paths\n",
    "repo_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(repo_root / \"src\"))\n",
    "\n",
    "# Import your modules\n",
    "from utils.audio_dataset_loader import preprocess_audio\n",
    "from deep_learning.gtcrn import GTCRN\n",
    "from dsp_algorithms.mband_var import mband\n",
    "from dsp_algorithms.wiener_as import wiener_filter\n",
    "\n",
    "# Initialize models\n",
    "print(\"Loading models...\")\n",
    "device = torch.device(\"cpu\")\n",
    "gtcrn_model = GTCRN().eval()\n",
    "ckpt_path = repo_root / \"src\" / \"deep_learning\" / \"gtcrn\" / \"gtcrn_main\" / \"checkpoints\" / \"model_trained_on_dns3.tar\"\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "gtcrn_model.load_state_dict(ckpt['model'])\n",
    "print(\"‚úì Models loaded successfully!\")\n",
    "\n",
    "# Define paths\n",
    "noise_path = repo_root / \"sound_data\" / \"raw\" / \"NOIZEUS_NOISE_DATASET\"\n",
    "clean_sound_path = repo_root / \"sound_data\" / \"raw\" / \"EARS_DATASET\" / \"p092\"\n",
    "\n",
    "# Noise file mapping\n",
    "NOISE_FILES = {\n",
    "    \"Cafeteria Babble\": \"cafeteria_babble.wav\",\n",
    "    \"Street Noise - Downtown\": \"Street Noise_downtown.wav\",\n",
    "    \"Street Noise\": \"Street Noise.wav\",\n",
    "    \"Car Noise (60mph)\": \"Car Noise_60mph.wav\",\n",
    "    \"Car Idle (40mph)\": \"Car Noise_Idle Noise_40mph.wav\",\n",
    "    \"Car Idle (60mph)\": \"Car Noise_Idle Noise_60mph.wav\",\n",
    "    \"Construction - Crane\": \"Construction_Crane_Moving.wav\",\n",
    "    \"Construction - Drilling\": \"Construction_Drilling.wav\",\n",
    "    \"Construction - Jackhammer 1\": \"Construction_Jackhammer1.wav\",\n",
    "    \"Construction - Jackhammer 2\": \"Construction_Jackhammer2.wav\",\n",
    "    \"Construction - Trucks\": \"Construction_Trucks_Unloading.wav\",\n",
    "    \"Inside Flight\": \"Inside Flight.wav\",\n",
    "    \"Inside Train 1\": \"Inside Train_1.wav\",\n",
    "    \"Inside Train 2\": \"Inside Train_2.wav\",\n",
    "    \"Inside Train 3\": \"Inside Train_3.wav\",\n",
    "    \"PC Fan\": \"PC Fan Noise.wav\",\n",
    "    \"SSN IEEE\": \"SSN_IEEE.wav\",\n",
    "    \"Train 1\": \"Train1.wav\",\n",
    "    \"Train 2\": \"Train2.wav\",\n",
    "    \"Water Cooler\": \"Water Cooler.wav\"\n",
    "}\n",
    "\n",
    "# Speech file mapping\n",
    "SPEECH_FILES = {\n",
    "    \"Amazement\": \"emo_amazement_freeform.wav\",\n",
    "    \"Anger\": \"emo_anger_freeform.wav\",\n",
    "    \"Disgust\": \"emo_disgust_freeform.wav\",\n",
    "    \"Fear\": \"emo_fear_freeform.wav\",\n",
    "    # \"Happiness\": \"emo_happiness_freeform.wav\",\n",
    "    \"Sadness\": \"emo_sadness_freeform.wav\"\n",
    "}\n",
    "\n",
    "# Global variables to store processed audio\n",
    "processed_audio = {}\n",
    "\n",
    "def calculate_metrics(clean, degraded, sample_rate):\n",
    "    \"\"\"Calculate speech quality metrics\"\"\"\n",
    "    from pesq import pesq\n",
    "    from pystoi import stoi\n",
    "    \n",
    "    # Ensure same length\n",
    "    min_len = min(len(clean), len(degraded))\n",
    "    clean = clean[:min_len]\n",
    "    degraded = degraded[:min_len]\n",
    "    \n",
    "    # Calculate PESQ (Perceptual Evaluation of Speech Quality)\n",
    "    try:\n",
    "        pesq_score = pesq(sample_rate, clean, degraded, 'wb')  # wideband\n",
    "    except:\n",
    "        pesq_score = None\n",
    "    \n",
    "    # Calculate STOI (Short-Time Objective Intelligibility)\n",
    "    try:\n",
    "        stoi_score = stoi(clean, degraded, sample_rate, extended=False)\n",
    "    except:\n",
    "        stoi_score = None\n",
    "    \n",
    "    # Calculate SNR\n",
    "    signal_power = np.sum(clean ** 2)\n",
    "    noise = degraded - clean\n",
    "    noise_power = np.sum(noise ** 2)\n",
    "    \n",
    "    if noise_power > 0:\n",
    "        snr = 10 * np.log10(signal_power / noise_power)\n",
    "    else:\n",
    "        snr = float('inf')\n",
    "    \n",
    "    return {\n",
    "        'pesq': pesq_score,\n",
    "        'stoi': stoi_score,\n",
    "        'snr': snr\n",
    "    }\n",
    "\n",
    "def process_audio_pipeline(clean_waveform, noise_waveform, noisy_speech, sample_rate):\n",
    "    \"\"\"Process audio through MBAND, Wiener, and GTCRN+MBAND pipelines\"\"\"\n",
    "    \n",
    "    # GTCRN inference\n",
    "    input_stft = torch.stft(noisy_speech, 512, 256, 512, torch.hann_window(512).pow(0.5), return_complex=True)\n",
    "    input_stft = torch.view_as_real(input_stft)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output_stft = gtcrn_model(input_stft[None])[0]\n",
    "    \n",
    "    output_stft = torch.complex(output_stft[..., 0], output_stft[..., 1])\n",
    "    gtcrn_enhanced = torch.istft(output_stft, 512, 256, 512, torch.hann_window(512).pow(0.5)).detach().cpu()\n",
    "    \n",
    "    # GTCRN + MBAND\n",
    "    gtcrn_mband_enh, _ = mband(\n",
    "        noisy_audio=gtcrn_enhanced.clone(),\n",
    "        fs=sample_rate,\n",
    "        Nband=8,\n",
    "        Freq_spacing='linear',\n",
    "        FRMSZ=20,\n",
    "        OVLP=75,\n",
    "        AVRGING=1,\n",
    "        Noisefr=1,\n",
    "        FLOOR=0.7,\n",
    "        VAD=1,\n",
    "    )\n",
    "    \n",
    "    # GTCRN + Wiener Filter\n",
    "    gtcrn_wiener_enh, _ = wiener_filter(\n",
    "        noisy_audio=gtcrn_enhanced.clone(),\n",
    "        fs=sample_rate,\n",
    "        frame_dur_ms=25,\n",
    "        mu=0.95,\n",
    "        a_dd=0.95,\n",
    "        eta=0.15\n",
    "    )\n",
    "    \n",
    "    return gtcrn_mband_enh, gtcrn_wiener_enh\n",
    "\n",
    "def plot_metrics(metrics_dict, mode):\n",
    "    \"\"\"Create interactive metrics comparison plot\"\"\"\n",
    "    \n",
    "    # Prepare data\n",
    "    methods = []\n",
    "    pesq_scores = []\n",
    "    stoi_scores = []\n",
    "    snr_scores = []\n",
    "    \n",
    "    for method, metrics in metrics_dict.items():\n",
    "        methods.append(method)\n",
    "        pesq_scores.append(metrics['pesq'] if metrics['pesq'] is not None else 0)\n",
    "        stoi_scores.append(metrics['stoi'] if metrics['stoi'] is not None else 0)\n",
    "        snr_scores.append(metrics['snr'])\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    \n",
    "    # Color scheme\n",
    "    colors = {\n",
    "        'Noisy': '#E53935',\n",
    "        'GTCRN+MBAND': '#1976D2', \n",
    "        'GTCRN+Wiener': '#7B1FA2'\n",
    "    }\n",
    "    \n",
    "    bar_colors = [colors[m] for m in methods]\n",
    "    \n",
    "    # PESQ plot\n",
    "    axes[0].bar(methods, pesq_scores, color=bar_colors, alpha=0.8, edgecolor='white', linewidth=2)\n",
    "    axes[0].set_ylabel('PESQ Score', fontweight='600', fontsize=11)\n",
    "    axes[0].set_title('Perceptual Speech Quality', fontweight='600', fontsize=12, pad=15)\n",
    "    axes[0].set_ylim([0, 5])\n",
    "    axes[0].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    axes[0].set_facecolor('#FAFAFA')\n",
    "    for spine in axes[0].spines.values():\n",
    "        spine.set_edgecolor('#E0E0E0')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(pesq_scores):\n",
    "        if v > 0:\n",
    "            axes[0].text(i, v + 0.1, f'{v:.2f}', ha='center', fontweight='600', fontsize=10)\n",
    "    \n",
    "    # STOI plot\n",
    "    axes[1].bar(methods, stoi_scores, color=bar_colors, alpha=0.8, edgecolor='white', linewidth=2)\n",
    "    axes[1].set_ylabel('STOI Score', fontweight='600', fontsize=11)\n",
    "    axes[1].set_title('Speech Intelligibility', fontweight='600', fontsize=12, pad=15)\n",
    "    axes[1].set_ylim([0, 1])\n",
    "    axes[1].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    axes[1].set_facecolor('#FAFAFA')\n",
    "    for spine in axes[1].spines.values():\n",
    "        spine.set_edgecolor('#E0E0E0')\n",
    "    \n",
    "    for i, v in enumerate(stoi_scores):\n",
    "        if v > 0:\n",
    "            axes[1].text(i, v + 0.02, f'{v:.2f}', ha='center', fontweight='600', fontsize=10)\n",
    "    \n",
    "    # SNR plot\n",
    "    axes[2].bar(methods, snr_scores, color=bar_colors, alpha=0.8, edgecolor='white', linewidth=2)\n",
    "    axes[2].set_ylabel('SNR (dB)', fontweight='600', fontsize=11)\n",
    "    axes[2].set_title('Signal-to-Noise Ratio', fontweight='600', fontsize=12, pad=15)\n",
    "    axes[2].grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    axes[2].set_facecolor('#FAFAFA')\n",
    "    for spine in axes[2].spines.values():\n",
    "        spine.set_edgecolor('#E0E0E0')\n",
    "    \n",
    "    for i, v in enumerate(snr_scores):\n",
    "        axes[2].text(i, v + 0.5, f'{v:.1f}', ha='center', fontweight='600', fontsize=10)\n",
    "    \n",
    "    # Rotate x labels\n",
    "    for ax in axes:\n",
    "        ax.tick_params(axis='x', rotation=15)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def on_process_button_clicked(b):\n",
    "    \"\"\"Handle process button click\"\"\"\n",
    "    global processed_audio\n",
    "    \n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Show processing message\n",
    "        display(HTML('''\n",
    "        <div style=\"padding: 20px; background: linear-gradient(135deg, #FFF8E1 0%, #FFE082 100%); \n",
    "                    border-radius: 12px; margin: 15px 0; box-shadow: 0 2px 8px rgba(0,0,0,0.1);\">\n",
    "            <div style=\"display: flex; align-items: center; gap: 12px;\">\n",
    "                <div style=\"font-size: 24px;\">‚è≥</div>\n",
    "                <div>\n",
    "                    <div style=\"font-weight: 600; color: #F57F17; font-size: 1.1em;\">Processing Audio</div>\n",
    "                    <div style=\"color: #F9A825; margin-top: 4px;\">This may take 10-30 seconds...</div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        '''))\n",
    "        \n",
    "        try:\n",
    "            # Get selected options\n",
    "            if use_upload_checkbox.value and uploaded_audio_data is not None:\n",
    "                # Use uploaded file\n",
    "                noisy_speech = uploaded_audio_data['waveform']\n",
    "                sample_rate = uploaded_audio_data['sample_rate']\n",
    "                clean_waveform = noisy_speech.clone()  # No clean reference for uploaded\n",
    "                noise_waveform = None\n",
    "                mode = \"uploaded\"\n",
    "            else:\n",
    "                # Use selected files\n",
    "                noise_file = NOISE_FILES[noise_dropdown.value]\n",
    "                speech_file = SPEECH_FILES[speech_dropdown.value]\n",
    "                snr_db = snr_slider.value\n",
    "                \n",
    "                noise_file_path = noise_path / noise_file\n",
    "                speech_file_path = clean_sound_path / speech_file\n",
    "                \n",
    "                # Preprocess audio\n",
    "                clean_waveform, noise_waveform, noisy_speech, sample_rate = preprocess_audio(\n",
    "                    clean_speech=speech_file_path,\n",
    "                    noisy_audio=noise_file_path,\n",
    "                    snr_db=snr_db\n",
    "                )\n",
    "                mode = \"generated\"\n",
    "            \n",
    "            # Process through pipelines\n",
    "            gtcrn_mband_enhanced, gtcrn_wiener_enhanced = process_audio_pipeline(\n",
    "                clean_waveform, noise_waveform, noisy_speech, sample_rate\n",
    "            )\n",
    "            \n",
    "            # Trim to same length\n",
    "            lengths = [len(noisy_speech.squeeze()), len(gtcrn_mband_enhanced.squeeze()), \n",
    "                      len(gtcrn_wiener_enhanced.squeeze())]\n",
    "            \n",
    "            if mode == \"generated\":\n",
    "                lengths.append(len(clean_waveform.squeeze()))\n",
    "                \n",
    "            min_len = min(lengths)\n",
    "            \n",
    "            noisy_trimmed = noisy_speech.squeeze()[:min_len]\n",
    "            gtcrn_mband_trimmed = gtcrn_mband_enhanced.squeeze()[:min_len]\n",
    "            gtcrn_wiener_trimmed = gtcrn_wiener_enhanced.squeeze()[:min_len]\n",
    "            \n",
    "            if mode == \"generated\":\n",
    "                clean_trimmed = clean_waveform.squeeze()[:min_len]\n",
    "            else:\n",
    "                clean_trimmed = None\n",
    "\n",
    "            # Calculate metrics if clean reference available\n",
    "            metrics_dict = None\n",
    "            if mode == \"generated\":\n",
    "                try:\n",
    "                    metrics_dict = {\n",
    "                        'Noisy': calculate_metrics(\n",
    "                            clean_trimmed.numpy(), \n",
    "                            noisy_trimmed.numpy(), \n",
    "                            sample_rate\n",
    "                        ),\n",
    "                        'GTCRN+MBAND': calculate_metrics(\n",
    "                            clean_trimmed.numpy(), \n",
    "                            gtcrn_mband_trimmed.numpy(), \n",
    "                            sample_rate\n",
    "                        ),\n",
    "                        'GTCRN+Wiener': calculate_metrics(\n",
    "                            clean_trimmed.numpy(), \n",
    "                            gtcrn_wiener_trimmed.numpy(), \n",
    "                            sample_rate\n",
    "                        )\n",
    "                    }\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not calculate metrics: {e}\")\n",
    "                    metrics_dict = None\n",
    "            \n",
    "            # Store results\n",
    "            processed_audio = {\n",
    "                'noisy': noisy_trimmed.numpy(),\n",
    "                'gtcrn_mband': gtcrn_mband_trimmed.numpy(),\n",
    "                'gtcrn_wiener': gtcrn_wiener_trimmed.numpy(),\n",
    "                'clean': clean_trimmed.numpy() if mode == \"generated\" else None,\n",
    "                'sample_rate': sample_rate,\n",
    "                'mode': mode, \n",
    "                'metrics': metrics_dict\n",
    "            }\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # Success message\n",
    "            display(HTML('''\n",
    "            <div style=\"padding: 20px; background: linear-gradient(135deg, #E8F5E9 0%, #A5D6A7 100%); \n",
    "                        border-radius: 12px; margin: 15px 0; box-shadow: 0 2px 8px rgba(0,0,0,0.1);\">\n",
    "                <div style=\"display: flex; align-items: center; gap: 12px;\">\n",
    "                    <div style=\"font-size: 24px;\">‚úÖ</div>\n",
    "                    <div>\n",
    "                        <div style=\"font-weight: 600; color: #2E7D32; font-size: 1.1em;\">Processing Complete</div>\n",
    "                        <div style=\"color: #43A047; margin-top: 4px;\">Listen to the enhanced audio below</div>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "            '''))\n",
    "\n",
    "             # Display metrics first if available\n",
    "            if metrics_dict is not None:\n",
    "                display(HTML('''\n",
    "                <div style=\"margin: 30px 0 20px 0;\">\n",
    "                    <h2 style=\"color: #1976D2; font-weight: 600; font-size: 1.5em; margin: 0;\">\n",
    "                        Speech Quality Metrics\n",
    "                    </h2>\n",
    "                    <div style=\"height: 3px; width: 60px; background: linear-gradient(90deg, #1976D2, #64B5F6); \n",
    "                                border-radius: 2px; margin-top: 8px;\"></div>\n",
    "                    <p style=\"color: #666; margin-top: 10px; font-size: 0.95em;\">\n",
    "                        Objective evaluation of speech enhancement performance\n",
    "                    </p>\n",
    "                </div>\n",
    "                '''))\n",
    "                \n",
    "                fig = plot_metrics(metrics_dict, mode)\n",
    "                plt.show()\n",
    "                \n",
    "                # Metrics explanation\n",
    "                display(HTML('''\n",
    "                <div style=\"background: white; padding: 18px; border-radius: 10px; margin: 15px 0; \n",
    "                            border-left: 4px solid #1976D2; box-shadow: 0 1px 4px rgba(0,0,0,0.08);\">\n",
    "                    <div style=\"color: #424242; font-size: 0.92em; line-height: 1.7;\">\n",
    "                        <strong style=\"color: #1976D2;\">PESQ:</strong> Perceptual quality (1-5, higher is better) | \n",
    "                        <strong style=\"color: #1976D2;\">STOI:</strong> Intelligibility (0-1, higher is better) | \n",
    "                        <strong style=\"color: #1976D2;\">SNR:</strong> Signal-to-noise ratio (dB, higher is better)\n",
    "                    </div>\n",
    "                </div>\n",
    "                '''))\n",
    "        \n",
    "            \n",
    "            # Display waveforms\n",
    "            display(HTML('''\n",
    "            <div style=\"margin: 30px 0 20px 0;\">\n",
    "                <h2 style=\"color: #1976D2; font-weight: 600; font-size: 1.5em; margin: 0;\">\n",
    "                    üìä Waveform Comparison\n",
    "                </h2>\n",
    "                <div style=\"height: 3px; width: 60px; background: linear-gradient(90deg, #1976D2, #64B5F6); \n",
    "                            border-radius: 2px; margin-top: 8px;\"></div>\n",
    "            </div>\n",
    "            '''))\n",
    "            \n",
    "            # Create figure with proper ordering\n",
    "            num_plots = 4 if mode == \"generated\" else 3\n",
    "            fig, axes = plt.subplots(num_plots, 1, figsize=(15, 3*num_plots))\n",
    "            if num_plots == 1:\n",
    "                axes = [axes]\n",
    "            \n",
    "            time_axis = np.arange(min_len) / sample_rate\n",
    "            \n",
    "            plot_idx = 0\n",
    "            \n",
    "            # 1. Clean Speech (if available)\n",
    "            if mode == \"generated\":\n",
    "                axes[plot_idx].plot(time_axis, clean_trimmed.numpy(), color='#43A047', alpha=0.8, linewidth=0.9)\n",
    "                axes[plot_idx].set_title('1. Clean Speech (Reference)', fontsize=13, fontweight='600', pad=12)\n",
    "                axes[plot_idx].set_ylabel('Amplitude', fontweight='500')\n",
    "                axes[plot_idx].grid(True, alpha=0.2, linestyle='--')\n",
    "                axes[plot_idx].set_facecolor('#FAFAFA')\n",
    "                axes[plot_idx].spines['top'].set_visible(False)\n",
    "                axes[plot_idx].spines['right'].set_visible(False)\n",
    "                plot_idx += 1\n",
    "            \n",
    "            # 2. Noisy Speech\n",
    "            axes[plot_idx].plot(time_axis, noisy_trimmed.numpy(), color='#E53935', alpha=0.8, linewidth=0.9)\n",
    "            axes[plot_idx].set_title(f'{plot_idx+1}. Noisy Speech', fontsize=13, fontweight='600', pad=12)\n",
    "            axes[plot_idx].set_ylabel('Amplitude', fontweight='500')\n",
    "            axes[plot_idx].grid(True, alpha=0.2, linestyle='--')\n",
    "            axes[plot_idx].set_facecolor('#FAFAFA')\n",
    "            axes[plot_idx].spines['top'].set_visible(False)\n",
    "            axes[plot_idx].spines['right'].set_visible(False)\n",
    "            plot_idx += 1\n",
    "            \n",
    "            # 3. GTCRN + MBAND\n",
    "            axes[plot_idx].plot(time_axis, gtcrn_mband_trimmed.numpy(), color='#1976D2', alpha=0.8, linewidth=0.9)\n",
    "            axes[plot_idx].set_title(f'{plot_idx+1}. GTCRN + MBAND Enhanced', fontsize=13, fontweight='600', pad=12)\n",
    "            axes[plot_idx].set_ylabel('Amplitude', fontweight='500')\n",
    "            axes[plot_idx].grid(True, alpha=0.2, linestyle='--')\n",
    "            axes[plot_idx].set_facecolor('#FAFAFA')\n",
    "            axes[plot_idx].spines['top'].set_visible(False)\n",
    "            axes[plot_idx].spines['right'].set_visible(False)\n",
    "            plot_idx += 1\n",
    "            \n",
    "            # 4. GTCRN + Wiener\n",
    "            axes[plot_idx].plot(time_axis, gtcrn_wiener_trimmed.numpy(), color='#7B1FA2', alpha=0.8, linewidth=0.9)\n",
    "            axes[plot_idx].set_title(f'{plot_idx+1}. GTCRN + Wiener Enhanced', fontsize=13, fontweight='600', pad=12)\n",
    "            axes[plot_idx].set_ylabel('Amplitude', fontweight='500')\n",
    "            axes[plot_idx].set_xlabel('Time (s)', fontweight='500')\n",
    "            axes[plot_idx].grid(True, alpha=0.2, linestyle='--')\n",
    "            axes[plot_idx].set_facecolor('#FAFAFA')\n",
    "            axes[plot_idx].spines['top'].set_visible(False)\n",
    "            axes[plot_idx].spines['right'].set_visible(False)\n",
    "            \n",
    "            plt.tight_layout(pad=2.0)\n",
    "            plt.show()\n",
    "            \n",
    "            # Display audio players\n",
    "            display(HTML('''\n",
    "            <div style=\"margin: 30px 0 20px 0;\">\n",
    "                <h2 style=\"color: #1976D2; font-weight: 600; font-size: 1.5em; margin: 0;\">\n",
    "                    üéß Audio Playback\n",
    "                </h2>\n",
    "                <div style=\"height: 3px; width: 60px; background: linear-gradient(90deg, #1976D2, #64B5F6); \n",
    "                            border-radius: 2px; margin-top: 8px;\"></div>\n",
    "            </div>\n",
    "            '''))\n",
    "            \n",
    "            play_idx = 1\n",
    "            \n",
    "            # Clean reference (if available)\n",
    "            # if mode == \"generated\":\n",
    "            #     display(HTML(f'''\n",
    "            #     <div style=\"background: white; padding: 20px; border-radius: 12px; margin: 15px 0; \n",
    "            #                 box-shadow: 0 2px 12px rgba(0,0,0,0.08); border-left: 4px solid #43A047;\">\n",
    "            #         <div style=\"font-weight: 600; font-size: 1.15em; color: #2E7D32; margin-bottom: 8px;\">\n",
    "            #             {play_idx}. Clean Speech (Reference)\n",
    "            #         </div>\n",
    "            #         <div style=\"color: #666; font-size: 0.95em; margin-bottom: 12px;\">\n",
    "            #             Original clean speech without noise\n",
    "            #         </div>\n",
    "            #     '''))\n",
    "            #     display(ipd.Audio(clean_trimmed.numpy(), rate=sample_rate))\n",
    "            #     display(HTML('</div>'))\n",
    "            #     play_idx += 1\n",
    "            \n",
    "            # Noisy\n",
    "            display(HTML(f'''\n",
    "            <div style=\"background: white; padding: 20px; border-radius: 12px; margin: 15px 0; \n",
    "                        box-shadow: 0 2px 12px rgba(0,0,0,0.08); border-left: 4px solid #E53935;\">\n",
    "                <div style=\"font-weight: 600; font-size: 1.15em; color: #C62828; margin-bottom: 8px;\">\n",
    "                    {play_idx}. Noisy Speech\n",
    "                </div>\n",
    "                <div style=\"color: #666; font-size: 0.95em; margin-bottom: 12px;\">\n",
    "                    Speech degraded by environmental noise\n",
    "                </div>\n",
    "            '''))\n",
    "            display(ipd.Audio(noisy_trimmed.numpy(), rate=sample_rate))\n",
    "            display(HTML('</div>'))\n",
    "            play_idx += 1\n",
    "            \n",
    "            # GTCRN + MBAND\n",
    "            display(HTML(f'''\n",
    "            <div style=\"background: white; padding: 20px; border-radius: 12px; margin: 15px 0; \n",
    "                        box-shadow: 0 2px 12px rgba(0,0,0,0.08); border-left: 4px solid #1976D2;\">\n",
    "                <div style=\"font-weight: 600; font-size: 1.15em; color: #1565C0; margin-bottom: 8px;\">\n",
    "                    {play_idx}. GTCRN + MBAND Enhanced\n",
    "                </div>\n",
    "                <div style=\"color: #666; font-size: 0.95em; margin-bottom: 12px;\">\n",
    "                    Deep learning (GTCRN) + Multi-band spectral subtraction\n",
    "                </div>\n",
    "            '''))\n",
    "            display(ipd.Audio(gtcrn_mband_trimmed.numpy(), rate=sample_rate))\n",
    "            display(HTML('</div>'))\n",
    "            play_idx += 1\n",
    "            \n",
    "            # GTCRN + Wiener\n",
    "            display(HTML(f'''\n",
    "            <div style=\"background: white; padding: 20px; border-radius: 12px; margin: 15px 0; \n",
    "                        box-shadow: 0 2px 12px rgba(0,0,0,0.08); border-left: 4px solid #7B1FA2;\">\n",
    "                <div style=\"font-weight: 600; font-size: 1.15em; color: #6A1B9A; margin-bottom: 8px;\">\n",
    "                    {play_idx}. GTCRN + Wiener Enhanced\n",
    "                </div>\n",
    "                <div style=\"color: #666; font-size: 0.95em; margin-bottom: 12px;\">\n",
    "                    Deep learning (GTCRN) + Wiener filter post-processing\n",
    "                </div>\n",
    "            '''))\n",
    "            display(ipd.Audio(gtcrn_wiener_trimmed.numpy(), rate=sample_rate))\n",
    "            display(HTML('</div>'))\n",
    "            \n",
    "        except Exception as e:\n",
    "            clear_output(wait=True)\n",
    "            display(HTML(f'''\n",
    "            <div style=\"padding: 20px; background: linear-gradient(135deg, #FFEBEE 0%, #EF9A9A 100%); \n",
    "                        border-radius: 12px; margin: 15px 0; box-shadow: 0 2px 8px rgba(0,0,0,0.1);\">\n",
    "                <div style=\"display: flex; align-items: center; gap: 12px;\">\n",
    "                    <div style=\"font-size: 24px;\">‚ùå</div>\n",
    "                    <div>\n",
    "                        <div style=\"font-weight: 600; color: #C62828; font-size: 1.1em;\">Processing Error</div>\n",
    "                        <div style=\"color: #E53935; margin-top: 4px;\">{str(e)}</div>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "            '''))\n",
    "\n",
    "# Store uploaded audio\n",
    "uploaded_audio_data = None\n",
    "\n",
    "def on_upload_change(change):\n",
    "    \"\"\"Handle file upload\"\"\"\n",
    "    global uploaded_audio_data\n",
    "    \n",
    "    with upload_output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        if change['new']:\n",
    "            try:\n",
    "                # Get the first uploaded file\n",
    "                file_info = change['new'][0] if isinstance(change['new'], (list, tuple)) else change['new']\n",
    "                \n",
    "                # Handle both old and new ipywidgets formats\n",
    "                if isinstance(file_info, dict):\n",
    "                    content = file_info['content']\n",
    "                else:\n",
    "                    content = file_info\n",
    "                \n",
    "                # Save temporarily\n",
    "                temp_path = Path(\"temp_uploaded.wav\")\n",
    "                \n",
    "                # Convert bytes to file\n",
    "                if isinstance(content, bytes):\n",
    "                    with open(temp_path, 'wb') as f:\n",
    "                        f.write(content)\n",
    "                else:\n",
    "                    # If it's already a file-like object\n",
    "                    with open(temp_path, 'wb') as f:\n",
    "                        f.write(content.read())\n",
    "                \n",
    "                # Load audio\n",
    "                waveform, sample_rate = torchaudio.load(temp_path)\n",
    "                \n",
    "                # Convert to mono if stereo\n",
    "                if waveform.shape[0] > 1:\n",
    "                    waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "                \n",
    "                # Resample to 16kHz if needed\n",
    "                if sample_rate != 16000:\n",
    "                    resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "                    waveform = resampler(waveform)\n",
    "                    sample_rate = 16000\n",
    "                \n",
    "                uploaded_audio_data = {\n",
    "                    'waveform': waveform,\n",
    "                    'sample_rate': sample_rate\n",
    "                }\n",
    "                \n",
    "                display(HTML(f'''\n",
    "                <div style=\"padding: 16px; background: linear-gradient(135deg, #E8F5E9 0%, #A5D6A7 100%); \n",
    "                            border-radius: 10px; border-left: 4px solid #43A047;\">\n",
    "                    <div style=\"font-weight: 600; color: #2E7D32; margin-bottom: 6px;\">‚úì File Uploaded Successfully</div>\n",
    "                    <div style=\"color: #43A047; font-size: 0.95em;\">\n",
    "                        Duration: {len(waveform[0])/sample_rate:.2f}s | Sample Rate: {sample_rate} Hz\n",
    "                    </div>\n",
    "                </div>\n",
    "                '''))\n",
    "                \n",
    "                # Clean up\n",
    "                temp_path.unlink()\n",
    "                \n",
    "            except Exception as e:\n",
    "                display(HTML(f'''\n",
    "                <div style=\"padding: 16px; background: linear-gradient(135deg, #FFEBEE 0%, #EF9A9A 100%); \n",
    "                            border-radius: 10px; border-left: 4px solid #E53935;\">\n",
    "                    <div style=\"font-weight: 600; color: #C62828; margin-bottom: 6px;\">Error Loading File</div>\n",
    "                    <div style=\"color: #E53935; font-size: 0.95em;\">{str(e)}</div>\n",
    "                </div>\n",
    "                '''))\n",
    "\n",
    "# Create GUI components with improved styling\n",
    "style = {'description_width': '160px'}\n",
    "layout = Layout(width='500px')\n",
    "\n",
    "# Header\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"background: linear-gradient(135deg, #1976D2 0%, #1565C0 100%); \n",
    "            padding: 40px; border-radius: 16px; margin-bottom: 30px; \n",
    "            box-shadow: 0 8px 32px rgba(25, 118, 210, 0.3);\">\n",
    "    <h1 style=\"margin: 0; font-size: 2.5em; color: white; font-weight: 600; letter-spacing: -0.5px;\">\n",
    "        üéµ Speech Enhancement System\n",
    "    </h1>\n",
    "    <p style=\"margin: 12px 0 0 0; font-size: 1.15em; color: rgba(255,255,255,0.95); font-weight: 400;\">\n",
    "        Advanced Audio Processing with Deep Learning & DSP Algorithms\n",
    "    </p>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "# Mode selection section\n",
    "display(HTML('''\n",
    "<div style=\"margin: 25px 0 15px 0;\">\n",
    "    <h2 style=\"color: #424242; font-weight: 600; font-size: 1.3em; margin: 0;\">\n",
    "        üìÅ Input Selection\n",
    "    </h2>\n",
    "    <div style=\"height: 3px; width: 50px; background: linear-gradient(90deg, #1976D2, #64B5F6); \n",
    "                border-radius: 2px; margin-top: 8px;\"></div>\n",
    "</div>\n",
    "'''))\n",
    "\n",
    "use_upload_checkbox = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Upload your own noisy audio file',\n",
    "    style=style,\n",
    "    layout=layout,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "upload_widget = widgets.FileUpload(\n",
    "    accept='.wav,.mp3',\n",
    "    multiple=False,\n",
    "    description='Select Audio File',\n",
    "    style=style,\n",
    "    layout=layout\n",
    ")\n",
    "upload_widget.observe(on_upload_change, names='value')\n",
    "\n",
    "upload_output = widgets.Output()\n",
    "\n",
    "display(use_upload_checkbox)\n",
    "display(upload_widget)\n",
    "display(upload_output)\n",
    "\n",
    "# Configuration section\n",
    "display(HTML('''\n",
    "<div style=\"margin: 30px 0 15px 0;\">\n",
    "    <h2 style=\"color: #424242; font-weight: 600; font-size: 1.3em; margin: 0;\">\n",
    "        üéõÔ∏è Audio Configuration\n",
    "    </h2>\n",
    "    <div style=\"height: 3px; width: 50px; background: linear-gradient(90deg, #1976D2, #64B5F6); \n",
    "                border-radius: 2px; margin-top: 8px;\"></div>\n",
    "    <p style=\"color: #757575; margin: 10px 0 15px 0; font-size: 0.95em;\">\n",
    "        Configure noise and speech settings (used when not uploading a file)\n",
    "    </p>\n",
    "</div>\n",
    "'''))\n",
    "\n",
    "noise_dropdown = widgets.Dropdown(\n",
    "    options=list(NOISE_FILES.keys()),\n",
    "    value='Street Noise - Downtown',\n",
    "    description='Noise Type:',\n",
    "    style=style,\n",
    "    layout=layout\n",
    ")\n",
    "\n",
    "speech_dropdown = widgets.Dropdown(\n",
    "    options=list(SPEECH_FILES.keys()),\n",
    "    value='Amazement',\n",
    "    description='Speech Emotion:',\n",
    "    style=style,\n",
    "    layout=layout\n",
    ")\n",
    "\n",
    "snr_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=-10,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='SNR Level (dB):',\n",
    "    style=style,\n",
    "    layout=layout,\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "display(noise_dropdown)\n",
    "display(speech_dropdown)\n",
    "display(snr_slider)\n",
    "display(HTML('''\n",
    "<p style=\"color: #757575; font-size: 0.9em; margin: 5px 0 0 165px; line-height: 1.5;\">\n",
    "    <strong>Lower values:</strong> More challenging noise conditions<br>\n",
    "    <strong>Higher values:</strong> Cleaner signal with less noise\n",
    "</p>\n",
    "'''))\n",
    "\n",
    "# Process button\n",
    "display(HTML('<div style=\"margin: 30px 0 20px 0;\">'))\n",
    "process_button = widgets.Button(\n",
    "    description='üéõÔ∏è  Process Audio',\n",
    "    button_style='',\n",
    "    layout=Layout(width='500px', height='56px'),\n",
    "    style={'button_color': '#1976D2', 'font_weight': '600', 'font_size': '16px'}\n",
    ")\n",
    "process_button.on_click(on_process_button_clicked)\n",
    "display(process_button)\n",
    "display(HTML('</div>'))\n",
    "\n",
    "# Output area\n",
    "output_area = widgets.Output()\n",
    "display(output_area)\n",
    "\n",
    "# Info box\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"background: linear-gradient(135deg, #E3F2FD 0%, #BBDEFB 100%); \n",
    "            padding: 20px; border-left: 4px solid #1976D2; \n",
    "            border-radius: 12px; margin-top: 30px; box-shadow: 0 2px 8px rgba(0,0,0,0.06);\">\n",
    "    <div style=\"color: #1565C0; line-height: 1.8;\">\n",
    "        <div style=\"font-weight: 600; font-size: 1.1em; margin-bottom: 10px;\">üí° Usage Instructions</div>\n",
    "        <div style=\"font-size: 0.95em;\">\n",
    "            <strong>1.</strong> Choose input method: Upload your noisy audio OR use predefined settings<br>\n",
    "            <strong>2.</strong> Click \"Process Audio\" and wait 10-30 seconds for processing<br>\n",
    "            <strong>3.</strong> Compare the enhancement techniques in waveforms and audio playback<br>\n",
    "            <strong>4.</strong> GTCRN + MBAND and GTCRN + Wiener offer state-of-the-art noise reduction\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
