{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe493053",
   "metadata": {},
   "source": [
    "# TinyNoiseGru Training Notebook\n",
    "\n",
    "Train a lightweight, causal GRU-based Noise Power Spectrum Estimator suitable for real-time hearing-aid applications.\n",
    "\n",
    "**Architecture Design:**\n",
    "- Based on TinyGRUVAD architecture (proven lightweight & causal)\n",
    "- Outputs noise power spectrum (mel bands) instead of binary VAD\n",
    "- ~2k parameters for efficient on-device deployment\n",
    "- Frame-level noise estimation with causal processing\n",
    "\n",
    "**Target Application:**\n",
    "- Real-time noise estimation for hearing-aid speech enhancement\n",
    "- Works with Wiener filtering, Spectral Subtraction.\n",
    "- Replaces traditional minimum statistics noise estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2934341",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9799f8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ------------------------- Cell 1: Imports & Setup ------------------------\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "import torchaudio, numpy as np, random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "SEED = 0\n",
    "torch.manual_seed(SEED); np.random.seed(SEED); random.seed(SEED)\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "repo_root = current_dir.parent.parent\n",
    "sys.path.insert(0, str(repo_root / \"src\"))\n",
    "\n",
    "print(\"Repo root:\", repo_root)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# helper utils\n",
    "from utils.audio_dataset_loader import (\n",
    "    load_ears_dataset, load_wham_dataset, load_noizeus_dataset,\n",
    "    create_audio_pairs, preprocess_audio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7def939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ------------------------- Cell 2: Global Plot Settings -------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set global plot parameters\n",
    "plt.rcParams['figure.dpi'] = 400\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 18\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['axes.titlesize'] = 18\n",
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['legend.fontsize'] = 18\n",
    "\n",
    "print(\"[INFO] Global plot settings applied: DPI=400, Font=Times New Roman 18pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ------------------------- Cell 3: TinyNoiseGru Model -------------------------\n",
    "class TinyNoiseGru(nn.Module):\n",
    "    \"\"\"Lightweight GRU-based Noise Power Spectrum Estimator.\n",
    "    \n",
    "    Args:\n",
    "        input_dim: Number of input features (default: 32 mel bands)\n",
    "        hidden_dim: GRU hidden size (default: 16, trade-off between capacity & efficiency)\n",
    "        dropout: Dropout rate (default: 0.1)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=32, hidden_dim=16, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Causal depthwise conv: captures local spectro-temporal patterns\n",
    "        self.pre = nn.Conv1d(input_dim, input_dim, kernel_size=3, padding=0, groups=input_dim)\n",
    "        self.norm = nn.LayerNorm(input_dim)\n",
    "        \n",
    "        # Single GRU layer: models temporal evolution of noise\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "        # Output layer: maps hidden state to noise power spectrum\n",
    "        self.fc = nn.Linear(hidden_dim, input_dim)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input features (B, T, F) where F = input_dim\n",
    "            h: Hidden state from previous time step (optional, for streaming)\n",
    "        \n",
    "        Returns:\n",
    "            noise_est: Estimated noise power spectrum (B, T, F)\n",
    "            h: Updated hidden state\n",
    "        \"\"\"\n",
    "        # x: (B,T,F)\n",
    "        x = x.transpose(1,2)              # (B,F,T)\n",
    "        \n",
    "        # Causal padding: pad (kernel_size-1) frames on the left only\n",
    "        # This ensures the conv doesn't see future frames\n",
    "        k = self.pre.kernel_size[0] if isinstance(self.pre.kernel_size, (list, tuple)) else self.pre.kernel_size\n",
    "        pad_left = k - 1\n",
    "        x = F.pad(x, (pad_left, 0))       # pad on time dimension (left, right)\n",
    "        \n",
    "        # Depthwise conv + normalization\n",
    "        x = self.pre(x).transpose(1,2)    # local causal conv -> (B,T,F)\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        # GRU: temporal modeling\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.drop(out)\n",
    "        \n",
    "        # Output: noise power spectrum estimate\n",
    "        # Use ReLU to ensure non-negative power values\n",
    "        noise_est = F.relu(self.fc(out))\n",
    "        \n",
    "        return noise_est, h\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"Count trainable parameters.\"\"\"\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140dbdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ------------------------- Cell 4: Load Datasets --------------------------\n",
    "max_pairs = 1000\n",
    "noise_files = load_wham_dataset(repo_root, mode=\"train\", max_files=max_pairs)\n",
    "clean_files = load_ears_dataset(repo_root, mode=\"train\")\n",
    "train_pairs = create_audio_pairs(noise_files, clean_files)\n",
    "print(f\"Train pairs: {len(train_pairs)}\")\n",
    "\n",
    "noise_val = load_wham_dataset(repo_root, mode=\"validation\", max_files=150)\n",
    "clean_val = load_ears_dataset(repo_root, mode=\"validation\")\n",
    "val_pairs = create_audio_pairs(noise_val, clean_val)\n",
    "print(f\"Val pairs: {len(val_pairs)}\")\n",
    "\n",
    "# Load TEST set (for final evaluation - never used during training)\n",
    "noise_test = load_wham_dataset(repo_root, mode=\"test\", max_files=150)\n",
    "clean_test = load_ears_dataset(repo_root, mode=\"test\")\n",
    "test_pairs = create_audio_pairs(noise_test, clean_val)\n",
    "print(f\"Test pairs: {len(test_pairs)}\")\n",
    "print(\"\\n [WARN] TEST SET: Only use for final evaluation, NOT during training/validation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ff60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ------------------------- Cell 5: Feature Extraction & Ground Truth -------------------------\n",
    "\n",
    "def extract_noise_estimation_features(noisy_wave, noise_wave, fs, n_bands=32, frame_len=0.008, hop_len=0.004):\n",
    "    \"\"\"Extract features and ground truth for noise estimation training.\n",
    "        \n",
    "    References:\n",
    "    - Cohen & Berdugo (2001) - \"Noise estimation by minima controlled recursive averaging\"\n",
    "    - Gerkmann & Hendriks (2012) - \"Unbiased MMSE-based noise power estimation\"\n",
    "    - Xu et al. (2014) - \"Regression approach to speech enhancement\"\n",
    "    \n",
    "    Args:\n",
    "        noisy_wave: Noisy input signal (clean speech + noise)\n",
    "        noise_wave: Pure noise signal (ground truth)\n",
    "        fs: Sample rate (typically 16000 Hz)\n",
    "        n_bands: Number of mel bands (default: 32)\n",
    "        frame_len: Frame length in seconds (default: 0.008 = 8ms)\n",
    "        hop_len: Hop length in seconds (default: 0.004 = 4ms)\n",
    "    \n",
    "    Returns:\n",
    "        feats: (1, T, 2*n_bands) feature tensor [log-mel + delta]\n",
    "        targets: (1, T, n_bands) ground truth noise power spectrum\n",
    "    \"\"\"\n",
    "    # Convert to mono: handle both stereo and mono inputs\n",
    "    if noisy_wave.dim() > 1 and noisy_wave.shape[0] > 1:\n",
    "        noisy_wave = noisy_wave.mean(dim=0)\n",
    "    elif noisy_wave.dim() > 1:\n",
    "        noisy_wave = noisy_wave[0]\n",
    "    \n",
    "    if noise_wave.dim() > 1 and noise_wave.shape[0] > 1:\n",
    "        noise_wave = noise_wave.mean(dim=0)\n",
    "    elif noise_wave.dim() > 1:\n",
    "        noise_wave = noise_wave[0]\n",
    "    \n",
    "    # Ensure both signals have same length (pad shorter one)\n",
    "    max_len = max(noisy_wave.shape[0], noise_wave.shape[0])\n",
    "    if noisy_wave.shape[0] < max_len:\n",
    "        noisy_wave = F.pad(noisy_wave, (0, max_len - noisy_wave.shape[0]))\n",
    "    if noise_wave.shape[0] < max_len:\n",
    "        noise_wave = F.pad(noise_wave, (0, max_len - noise_wave.shape[0]))\n",
    "    \n",
    "    n_fft, hop = int(fs*frame_len), int(fs*hop_len)\n",
    "    win = torch.hann_window(n_fft)\n",
    "\n",
    "    def power_spectrum(w): \n",
    "        # center=False -> causal framing (no future samples)\n",
    "        spec = torch.stft(w, n_fft, hop, window=win, center=False, return_complex=True)\n",
    "        return spec.abs()**2\n",
    "\n",
    "    mel_transform = torchaudio.transforms.MelScale(n_mels=n_bands, sample_rate=fs, n_stft=n_fft//2+1)\n",
    "    \n",
    "    # ============ FEATURES: Extract from NOISY audio (realistic input) ============\n",
    "    mel_noisy = mel_transform(power_spectrum(noisy_wave)).clamp_min(1e-8)\n",
    "    log_mel = torch.log(mel_noisy.T + 1e-8)  # (T, n_bands)\n",
    "    \n",
    "    # Delta features: temporal derivative (captures noise evolution)\n",
    "    delta = torch.zeros_like(log_mel)\n",
    "    delta[1:] = log_mel[1:] - log_mel[:-1]\n",
    "    \n",
    "    feats = torch.cat([log_mel, delta], 1).unsqueeze(0)  # (1, T, 2*n_bands)\n",
    "    \n",
    "    # ============ TARGETS: Extract from PURE NOISE (ground truth) ============\n",
    "    mel_noise = mel_transform(power_spectrum(noise_wave))  # (n_bands, T)\n",
    "    noise_power = mel_noise.T.clamp_min(1e-8)  # (T, n_bands)\n",
    "    targets = noise_power.unsqueeze(0)  # (1, T, n_bands)\n",
    "    \n",
    "    # Ensure features and targets have same temporal dimension\n",
    "    min_frames = min(feats.size(1), targets.size(1))\n",
    "    feats = feats[:, :min_frames, :]\n",
    "    targets = targets[:, :min_frames, :]\n",
    "    \n",
    "    return feats, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a38b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ------------------------- Cell 6: Dataset & Loader -----------------------\n",
    "class NoiseEstimationDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset for training TinyNoiseGru.\n",
    "    \n",
    "    Each sample:\n",
    "    - Loads a clean speech file and a noise file\n",
    "    - Mixes them at a random SNR\n",
    "    - Extracts features from noisy mixture\n",
    "    - Extracts ground truth from pure noise\n",
    "    \"\"\"\n",
    "    def __init__(self, pairs, target_sr=16_000, snr_range=(-5, 15)):\n",
    "        self.pairs = pairs\n",
    "        self.sr = target_sr\n",
    "        self.snr_range = snr_range\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        noise_path, clean_path = self.pairs[idx]\n",
    "        snr = random.uniform(*self.snr_range)\n",
    "        \n",
    "        # preprocess_audio returns: clean_wave, noise_wave, noisy_wave, fs\n",
    "        clean_wave, noise_wave, noisy_wave, fs = preprocess_audio(\n",
    "            Path(clean_path), Path(noise_path), self.sr, snr, None\n",
    "        )\n",
    "        \n",
    "        # Extract features and targets\n",
    "        feats, targets = extract_noise_estimation_features(noisy_wave, noise_wave, fs)\n",
    "        \n",
    "        return feats.squeeze(0), targets.squeeze(0)\n",
    "\n",
    "\n",
    "def collate_pad_noise(batch):\n",
    "    \"\"\"Collate function for variable-length sequences.\n",
    "    \n",
    "    Pads all sequences to the maximum length in the batch.\n",
    "    \"\"\"\n",
    "    feats, targets = zip(*batch)\n",
    "    lengths = [f.size(0) for f in feats]\n",
    "    T_max = max(lengths)\n",
    "    F_dim = feats[0].size(1)\n",
    "    T_dim = targets[0].size(1)\n",
    "    \n",
    "    X = torch.zeros(len(batch), T_max, F_dim)\n",
    "    Y = torch.zeros(len(batch), T_max, T_dim)\n",
    "    \n",
    "    for i, (f, t) in enumerate(zip(feats, targets)):\n",
    "        X[i, :f.size(0)] = f\n",
    "        Y[i, :t.size(0)] = t\n",
    "    \n",
    "    return X, Y, torch.tensor(lengths)\n",
    "\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_ds = NoiseEstimationDataset(train_pairs)\n",
    "val_ds = NoiseEstimationDataset(val_pairs)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=8, shuffle=True, \n",
    "    collate_fn=collate_pad_noise, pin_memory=True\n",
    ")\n",
    "val_dl = torch.utils.data.DataLoader(\n",
    "    val_ds, batch_size=8, \n",
    "    collate_fn=collate_pad_noise, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"[INFO] Train batches: {len(train_dl)}\")\n",
    "print(f\"[INFO] Val batches: {len(val_dl)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85db1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ------------------------- Cell 7: Training Loop -------------------------\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from IPython.display import clear_output, display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize model\n",
    "N_BANDS = 32  # Number of mel bands\n",
    "model = TinyNoiseGru(input_dim=N_BANDS, hidden_dim=16).to(device)\n",
    "print(f\"[INFO] Model parameters: {model.count_parameters():,}\")\n",
    "\n",
    "# Optimizer and scheduler\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"min\", factor=0.5, patience=3)\n",
    "\n",
    "# Loss function: MSE for regression\n",
    "# Note: We'll compute per-frame loss and average over valid frames\n",
    "crit = nn.MSELoss(reduction='none')\n",
    "\n",
    "# Model saving paths\n",
    "best_mse = float('inf')\n",
    "bestPath = repo_root / \"models\" / \"GRU_NoiseEst\" / \"tiny_noise_gru_best.pth\"\n",
    "bestPath.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create directory for checkpoints\n",
    "models_dir = repo_root / \"models\" / \"GRU_NoiseEst\" / \"training_checkpoints\"\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"[INFO] Checkpoint directory: {models_dir}\")\n",
    "\n",
    "# Create directory for training data\n",
    "training_data_dir = repo_root / \"results\" / \"GRU_NoiseEst\" / \"training_data\"\n",
    "training_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"[INFO] Training data directory: {training_data_dir}\")\n",
    "\n",
    "# Training configuration\n",
    "num_epochs = 50  # Number of training epochs\n",
    "early_stop_patience = 20\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# LR warmup function\n",
    "def lr_warmup(epoch, warmup_epochs=5, base_lr=1e-3):\n",
    "    \"\"\"Linear warmup for first few epochs.\"\"\"\n",
    "    if epoch < warmup_epochs:\n",
    "        return base_lr * (epoch + 1) / warmup_epochs\n",
    "    return base_lr\n",
    "\n",
    "# Prepare live plotting\n",
    "plt.ion()\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "ax_loss, ax_mae, ax_rel, ax_lr = axes.flatten()\n",
    "\n",
    "ax_loss.set_title(\"MSE Loss\"); ax_loss.set_xlabel(\"Epoch\"); ax_loss.set_ylabel(\"MSE\"); ax_loss.grid(True, alpha=0.3)\n",
    "ax_mae.set_title(\"MAE Loss\"); ax_mae.set_xlabel(\"Epoch\"); ax_mae.set_ylabel(\"MAE\"); ax_mae.grid(True, alpha=0.3)\n",
    "ax_rel.set_title(\"Relative Error\"); ax_rel.set_xlabel(\"Epoch\"); ax_rel.set_ylabel(\"Rel. Error (%)\"); ax_rel.grid(True, alpha=0.3)\n",
    "ax_lr.set_title(\"Learning Rate\"); ax_lr.set_xlabel(\"Epoch\"); ax_lr.set_ylabel(\"LR\"); ax_lr.grid(True, alpha=0.3)\n",
    "\n",
    "# Metrics storage\n",
    "train_losses, val_losses = [], []\n",
    "train_mae, val_mae = [], []\n",
    "train_rel_err, val_rel_err = [], []\n",
    "lr_history = []\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING: TinyNoiseGru - Lightweight Noise Power Spectrum Estimator\")\n",
    "print(f\"Total Epochs: {num_epochs} | Early Stop Patience: {early_stop_patience}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Apply LR warmup\n",
    "    current_lr = lr_warmup(epoch, warmup_epochs=5)\n",
    "    for param_group in opt.param_groups:\n",
    "        param_group['lr'] = current_lr\n",
    "    lr_history.append(current_lr)\n",
    "    \n",
    "    # ---------------- Train ----------------\n",
    "    model.train()\n",
    "    train_mse_total = 0.0\n",
    "    train_mae_total = 0.0\n",
    "    train_rel_total = 0.0\n",
    "    train_samples = 0\n",
    "    \n",
    "    for x, y, lengths in tqdm(train_dl, desc=f\"Epoch {epoch}/{num_epochs}\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        noise_est, _ = model(x)\n",
    "        \n",
    "        # Compute loss only on valid (non-padded) frames\n",
    "        B, T_max = noise_est.size(0), noise_est.size(1)\n",
    "        mask = (torch.arange(T_max, device=lengths.device)[None, :] < lengths[:, None]).to(device)\n",
    "        \n",
    "        # MSE loss\n",
    "        loss_per_frame = crit(noise_est, y).mean(dim=-1)  # Average over frequency bins\n",
    "        loss = (loss_per_frame * mask).sum() / mask.sum().clamp_min(1.0)\n",
    "        \n",
    "        # Backward pass\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping (prevent exploding gradients)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        opt.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        with torch.no_grad():\n",
    "            # MSE\n",
    "            train_mse_total += loss.item() * mask.sum().item()\n",
    "            \n",
    "            # MAE\n",
    "            mae_per_frame = torch.abs(noise_est - y).mean(dim=-1)\n",
    "            train_mae_total += (mae_per_frame * mask).sum().item()\n",
    "            \n",
    "            # Relative error: |pred - true| / true\n",
    "            rel_err = torch.abs(noise_est - y) / (y + 1e-8)\n",
    "            train_rel_total += (rel_err.mean(dim=-1) * mask).sum().item()\n",
    "            \n",
    "            train_samples += mask.sum().item()\n",
    "    \n",
    "    # Average training metrics\n",
    "    train_mse = train_mse_total / train_samples\n",
    "    train_mae_epoch = train_mae_total / train_samples\n",
    "    train_rel_epoch = (train_rel_total / train_samples) * 100  # Convert to percentage\n",
    "    \n",
    "    train_losses.append(train_mse)\n",
    "    train_mae.append(train_mae_epoch)\n",
    "    train_rel_err.append(train_rel_epoch)\n",
    "    \n",
    "    # ---------------- Validate ----------------\n",
    "    model.eval()\n",
    "    val_mse_total = 0.0\n",
    "    val_mae_total = 0.0\n",
    "    val_rel_total = 0.0\n",
    "    val_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y, lengths in val_dl:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            noise_est, _ = model(x)\n",
    "            \n",
    "            # Compute metrics on valid frames\n",
    "            B, T_max = noise_est.size(0), noise_est.size(1)\n",
    "            mask = (torch.arange(T_max, device=lengths.device)[None, :] < lengths[:, None]).to(device)\n",
    "            \n",
    "            # MSE\n",
    "            loss_per_frame = ((noise_est - y) ** 2).mean(dim=-1)\n",
    "            val_mse_total += (loss_per_frame * mask).sum().item()\n",
    "            \n",
    "            # MAE\n",
    "            mae_per_frame = torch.abs(noise_est - y).mean(dim=-1)\n",
    "            val_mae_total += (mae_per_frame * mask).sum().item()\n",
    "            \n",
    "            # Relative error\n",
    "            rel_err = torch.abs(noise_est - y) / (y + 1e-8)\n",
    "            val_rel_total += (rel_err.mean(dim=-1) * mask).sum().item()\n",
    "            \n",
    "            val_samples += mask.sum().item()\n",
    "    \n",
    "    # Average validation metrics\n",
    "    val_mse = val_mse_total / val_samples\n",
    "    val_mae_epoch = val_mae_total / val_samples\n",
    "    val_rel_epoch = (val_rel_total / val_samples) * 100\n",
    "    \n",
    "    val_losses.append(val_mse)\n",
    "    val_mae.append(val_mae_epoch)\n",
    "    val_rel_err.append(val_rel_epoch)\n",
    "    \n",
    "    # Update scheduler\n",
    "    sched.step(val_mse)\n",
    "    \n",
    "    # ---------------- Save Best Model ----------------\n",
    "    if val_mse < best_mse:\n",
    "        best_mse = val_mse\n",
    "        torch.save(model.state_dict(), bestPath)\n",
    "        \n",
    "        # Save checkpoint with epoch number\n",
    "        checkpoint_path = models_dir / f\"tiny_noise_gru_epoch_{epoch:03d}_mse_{val_mse:.6f}.pth\"\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        \n",
    "        epochs_without_improvement = 0\n",
    "        status = f\"[INFO] NEW BEST (MSE={val_mse:.6f}) - Saved epoch {epoch}\"\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        status = f\"[DEBUG] (No improvement: {epochs_without_improvement}/{early_stop_patience})\"\n",
    "    \n",
    "    # ---------------- Display ----------------\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Epoch {epoch:2d}/{num_epochs}  LR={current_lr:.1e}\")\n",
    "    print(f\"  Train: MSE={train_mse:.6f}  MAE={train_mae_epoch:.6f}  RelErr={train_rel_epoch:.2f}%\")\n",
    "    print(f\"  Val:   MSE={val_mse:.6f}  MAE={val_mae_epoch:.6f}  RelErr={val_rel_epoch:.2f}%\")\n",
    "    print(f\"  {status}\")\n",
    "    \n",
    "    # Update plots\n",
    "    for ax in axes.flatten():\n",
    "        ax.cla()\n",
    "    \n",
    "    # MSE Loss plot\n",
    "    ax_loss.plot(train_losses, \"b-\", label=\"Train MSE\", linewidth=2)\n",
    "    ax_loss.plot(val_losses, \"r-\", label=\"Val MSE\", linewidth=2)\n",
    "    ax_loss.legend(); ax_loss.set_xlabel(\"Epoch\"); ax_loss.set_ylabel(\"MSE\")\n",
    "    ax_loss.set_title(\"MSE Loss\"); ax_loss.grid(True, alpha=0.3)\n",
    "    \n",
    "    # MAE plot\n",
    "    ax_mae.plot(train_mae, \"b-\", label=\"Train MAE\", linewidth=2)\n",
    "    ax_mae.plot(val_mae, \"r-\", label=\"Val MAE\", linewidth=2)\n",
    "    ax_mae.legend(); ax_mae.set_xlabel(\"Epoch\"); ax_mae.set_ylabel(\"MAE\")\n",
    "    ax_mae.set_title(\"MAE Loss\"); ax_mae.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Relative Error plot\n",
    "    ax_rel.plot(train_rel_err, \"b-\", label=\"Train Rel. Err\", linewidth=2)\n",
    "    ax_rel.plot(val_rel_err, \"r-\", label=\"Val Rel. Err\", linewidth=2)\n",
    "    ax_rel.legend(); ax_rel.set_xlabel(\"Epoch\"); ax_rel.set_ylabel(\"Rel. Error (%)\")\n",
    "    ax_rel.set_title(\"Relative Error\"); ax_rel.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning Rate plot\n",
    "    ax_lr.plot(lr_history, \"g-\", linewidth=2)\n",
    "    ax_lr.set_xlabel(\"Epoch\"); ax_lr.set_ylabel(\"LR\")\n",
    "    ax_lr.set_title(\"Learning Rate\"); ax_lr.grid(True, alpha=0.3)\n",
    "    ax_lr.set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    display(fig)\n",
    "    plt.pause(0.001)\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_without_improvement >= early_stop_patience:\n",
    "        print(f\"\\n[INFO] Early stopping: No improvement for {early_stop_patience} epochs\")\n",
    "        print(f\"       Best MSE: {best_mse:.6f}\")\n",
    "        break\n",
    "    \n",
    "    # Secondary stopping: LR floor\n",
    "    if current_lr < 1e-5:\n",
    "        print(f\"\\n[INFO] LR floor reached: Stopping training\")\n",
    "        break\n",
    "\n",
    "# Save training metrics to CSV\n",
    "print(\"\\n[INFO] Saving training metrics to CSV...\")\n",
    "metrics_df = pd.DataFrame({\n",
    "    'epoch': list(range(1, len(train_losses) + 1)),\n",
    "    'train_mse': train_losses,\n",
    "    'val_mse': val_losses,\n",
    "    'train_mae': train_mae,\n",
    "    'val_mae': val_mae,\n",
    "    'train_rel_err': train_rel_err,\n",
    "    'val_rel_err': val_rel_err,\n",
    "    'learning_rate': lr_history[:len(train_losses)]\n",
    "})\n",
    "\n",
    "csv_path = training_data_dir / \"tiny_noise_gru_training_metrics.csv\"\n",
    "metrics_df.to_csv(csv_path, index=False)\n",
    "print(f\"[INFO] Metrics saved to: {csv_path}\")\n",
    "\n",
    "# Save final plot\n",
    "plt.ioff()\n",
    "fig_path = training_data_dir / \"tiny_noise_gru_training_curves.png\"\n",
    "fig.savefig(fig_path, dpi=400, bbox_inches='tight')\n",
    "print(f\"[INFO] Training curves saved to: {fig_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"TRAINING COMPLETE - Best validation MSE: {best_mse:.6f}\")\n",
    "print(f\"Model saved to: {bestPath}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fa6197",
   "metadata": {},
   "source": [
    "## Evaluation & Visualization\n",
    "\n",
    "Let's evaluate the trained model and visualize some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460e21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ------------------------- Cell 8: Evaluation on Test Set -------------------------\n",
    "print(\"\\n[INFO] Evaluating on TEST set...\")\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(bestPath))\n",
    "model.eval()\n",
    "\n",
    "# Create test dataset\n",
    "test_ds = NoiseEstimationDataset(test_pairs)\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "    test_ds, batch_size=8, \n",
    "    collate_fn=collate_pad_noise, pin_memory=True\n",
    ")\n",
    "\n",
    "test_mse_total = 0.0\n",
    "test_mae_total = 0.0\n",
    "test_rel_total = 0.0\n",
    "test_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y, lengths in tqdm(test_dl, desc=\"Testing\"):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        noise_est, _ = model(x)\n",
    "        \n",
    "        # Compute metrics on valid frames\n",
    "        B, T_max = noise_est.size(0), noise_est.size(1)\n",
    "        mask = (torch.arange(T_max, device=lengths.device)[None, :] < lengths[:, None]).to(device)\n",
    "        \n",
    "        # MSE\n",
    "        loss_per_frame = ((noise_est - y) ** 2).mean(dim=-1)\n",
    "        test_mse_total += (loss_per_frame * mask).sum().item()\n",
    "        \n",
    "        # MAE\n",
    "        mae_per_frame = torch.abs(noise_est - y).mean(dim=-1)\n",
    "        test_mae_total += (mae_per_frame * mask).sum().item()\n",
    "        \n",
    "        # Relative error\n",
    "        rel_err = torch.abs(noise_est - y) / (y + 1e-8)\n",
    "        test_rel_total += (rel_err.mean(dim=-1) * mask).sum().item()\n",
    "        \n",
    "        test_samples += mask.sum().item()\n",
    "\n",
    "# Average test metrics\n",
    "test_mse = test_mse_total / test_samples\n",
    "test_mae = test_mae_total / test_samples\n",
    "test_rel_err = (test_rel_total / test_samples) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"  MSE:              {test_mse:.6f}\")\n",
    "print(f\"  MAE:              {test_mae:.6f}\")\n",
    "print(f\"  Relative Error:   {test_rel_err:.2f}%\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save test results\n",
    "test_results = {\n",
    "    'test_mse': test_mse,\n",
    "    'test_mae': test_mae,\n",
    "    'test_rel_err': test_rel_err\n",
    "}\n",
    "\n",
    "import json\n",
    "results_path = training_data_dir / \"tiny_noise_gru_test_results.json\"\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(test_results, f, indent=2)\n",
    "print(f\"\\n[INFO] Test results saved to: {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f793a385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ------------------------- Cell 9: Visualize Predictions -------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get a random sample from test set\n",
    "test_idx = random.randint(0, len(test_ds) - 1)\n",
    "feats, targets = test_ds[test_idx]\n",
    "\n",
    "# Add batch dimension and move to device\n",
    "feats_batch = feats.unsqueeze(0).to(device)\n",
    "targets_batch = targets.unsqueeze(0).to(device)\n",
    "\n",
    "# Get prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred, _ = model(feats_batch)\n",
    "\n",
    "# Move to CPU and remove batch dimension\n",
    "pred = pred.squeeze(0).cpu().numpy()\n",
    "targets = targets.squeeze(0).cpu().numpy()\n",
    "feats = feats.cpu().numpy()\n",
    "\n",
    "# Extract log-mel features (first half of feature vector)\n",
    "log_mel = feats[:, :N_BANDS]\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Input log-mel spectrogram\n",
    "ax1 = axes[0]\n",
    "im1 = ax1.imshow(log_mel.T, aspect='auto', origin='lower', cmap='viridis')\n",
    "ax1.set_title(\"Input: Log-Mel Spectrogram (Noisy)\")\n",
    "ax1.set_xlabel(\"Frame\")\n",
    "ax1.set_ylabel(\"Mel Band\")\n",
    "plt.colorbar(im1, ax=ax1, label=\"Log Power\")\n",
    "\n",
    "# Plot 2: Ground truth noise power\n",
    "ax2 = axes[1]\n",
    "im2 = ax2.imshow(targets.T, aspect='auto', origin='lower', cmap='hot')\n",
    "ax2.set_title(\"Ground Truth: Noise Power Spectrum\")\n",
    "ax2.set_xlabel(\"Frame\")\n",
    "ax2.set_ylabel(\"Mel Band\")\n",
    "plt.colorbar(im2, ax=ax2, label=\"Power\")\n",
    "\n",
    "# Plot 3: Predicted noise power\n",
    "ax3 = axes[2]\n",
    "im3 = ax3.imshow(pred.T, aspect='auto', origin='lower', cmap='hot')\n",
    "ax3.set_title(\"Predicted: Noise Power Spectrum\")\n",
    "ax3.set_xlabel(\"Frame\")\n",
    "ax3.set_ylabel(\"Mel Band\")\n",
    "plt.colorbar(im3, ax=ax3, label=\"Power\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute per-frame error\n",
    "frame_mse = np.mean((pred - targets) ** 2, axis=1)\n",
    "frame_mae = np.mean(np.abs(pred - targets), axis=1)\n",
    "\n",
    "# Plot error over time\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 6))\n",
    "\n",
    "ax1 = axes[0]\n",
    "ax1.plot(frame_mse, 'b-', linewidth=1.5)\n",
    "ax1.set_title(\"Per-Frame MSE\")\n",
    "ax1.set_xlabel(\"Frame\")\n",
    "ax1.set_ylabel(\"MSE\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = axes[1]\n",
    "ax2.plot(frame_mae, 'r-', linewidth=1.5)\n",
    "ax2.set_title(\"Per-Frame MAE\")\n",
    "ax2.set_xlabel(\"Frame\")\n",
    "ax2.set_ylabel(\"MAE\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Sample {test_idx} - Average MSE: {np.mean(frame_mse):.6f}, Average MAE: {np.mean(frame_mae):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efacfd5b",
   "metadata": {},
   "source": [
    "## Model Analysis\n",
    "\n",
    "Let's analyze the model's performance characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8831cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ------------------------- Cell 10: Model Performance Analysis -------------------------\n",
    "\n",
    "# Analyze model size and efficiency\n",
    "total_params = model.count_parameters()\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Model size: {total_params * 4 / 1024:.2f} KB (float32)\")\n",
    "\n",
    "# Analyze computational complexity (FLOPs per frame)\n",
    "# Rough estimate for hearing-aid deployment\n",
    "print(\"\\n[INFO] Computational Complexity Estimate:\")\n",
    "print(f\"  - Conv1d: {N_BANDS * 3} FLOPs\")\n",
    "print(f\"  - GRU: {3 * 16 * (N_BANDS + 16 + 1)} FLOPs\")\n",
    "print(f\"  - FC: {16 * N_BANDS} FLOPs\")\n",
    "print(f\"  - Total: ~{N_BANDS * 3 + 3 * 16 * (N_BANDS + 16 + 1) + 16 * N_BANDS} FLOPs per frame\")\n",
    "print(f\"  - At 250 fps: ~{(N_BANDS * 3 + 3 * 16 * (N_BANDS + 16 + 1) + 16 * N_BANDS) * 250 / 1e6:.2f} MFLOPs/sec\")\n",
    "\n",
    "# Memory footprint for streaming (single frame processing)\n",
    "print(f\"\\n[INFO] Memory Footprint:\")\n",
    "print(f\"  - Model weights: {total_params * 4 / 1024:.2f} KB\")\n",
    "print(f\"  - Hidden state: {16 * 4} bytes = {16 * 4 / 1024:.3f} KB\")\n",
    "print(f\"  - Input buffer (3 frames): {N_BANDS * 3 * 4 / 1024:.3f} KB\")\n",
    "print(f\"  - Total: ~{(total_params * 4 + 16 * 4 + N_BANDS * 3 * 4) / 1024:.2f} KB\")\n",
    "print(\"\\n[SUCCESS] Model is lightweight enough for hearing-aid deployment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b445a0bc",
   "metadata": {},
   "source": [
    "## Export Model for Inference\n",
    "\n",
    "Export the trained model for use in speech enhancement algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06edcb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ------------------------- Cell 11: Export Model -------------------------\n",
    "\n",
    "# Save model architecture + weights in a single file\n",
    "export_path = repo_root / \"models\" / \"GRU_NoiseEst\" / \"tiny_noise_gru_complete.pth\"\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_config': {\n",
    "        'input_dim': N_BANDS,\n",
    "        'hidden_dim': 16,\n",
    "        'dropout': 0.1\n",
    "    },\n",
    "    'training_config': {\n",
    "        'n_bands': N_BANDS,\n",
    "        'frame_len': 0.008,\n",
    "        'hop_len': 0.004,\n",
    "        'sample_rate': 16000\n",
    "    },\n",
    "    'performance': {\n",
    "        'best_val_mse': best_mse,\n",
    "        'test_mse': test_mse,\n",
    "        'test_mae': test_mae,\n",
    "        'test_rel_err': test_rel_err\n",
    "    }\n",
    "}, export_path)\n",
    "\n",
    "print(f\"[INFO] Complete model exported to: {export_path}\")\n",
    "print(\"\\nTo load the model:\")\n",
    "print(\"```python\")\n",
    "print(\"checkpoint = torch.load('tiny_noise_gru_complete.pth')\")\n",
    "print(\"config = checkpoint['model_config']\")\n",
    "print(\"model = TinyNoiseGru(**config)\")\n",
    "print(\"model.load_state_dict(checkpoint['model_state_dict'])\")\n",
    "print(\"```\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
