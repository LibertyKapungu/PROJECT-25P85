{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731c6d98",
   "metadata": {},
   "source": [
    "# Experiment WF_EXP2p2a: Wiener Filter with NVIDIA MarbleNet VAD Integration\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides a comprehensive analysis of the WF_EXP2p2a experiment, which evaluates \n",
    "the performance of a causal Wiener filter enhanced with voice activity detection (VAD) using \n",
    "NVIDIA's MarbleNet model.\n",
    "\n",
    "## Experiment Details\n",
    "\n",
    "### System Configuration\n",
    "- **VAD Model**: NVIDIA MarbleNet (lightweight, efficient neural VAD)\n",
    "- **Filter Type**: Causal Wiener filter\n",
    "- **Frame Duration**: 20ms (default parameters)\n",
    "- **VAD Thresholds Tested**: 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60\n",
    "\n",
    "### Key Features\n",
    "- MarbleNet is a lightweight, efficient VAD network designed for real-time processing\n",
    "- Causal implementation suitable for low-latency applications\n",
    "- Multiple threshold testing to optimize speech/non-speech detection\n",
    "- Focuses noise reduction on detected speech segments\n",
    "\n",
    "### Comparison Systems\n",
    "1. **BASELINE**: Noisy speech without enhancement\n",
    "2. **WF_EXP1p1c**: Wiener filter without VAD (8ms frames)\n",
    "3. **WF_EXP2p2a**: Wiener filter with MarbleNet VAD (20ms frames, variable threshold)\n",
    "\n",
    "### Test Conditions\n",
    "- **Datasets**: EARS (clean speech) + NOIZEUS (noise)\n",
    "- **SNR Levels**: -5, 0, 5, 10, 15 dB\n",
    "- **Metrics**: PESQ, STOI, SI-SDR, DNSMOS\n",
    "\n",
    "## Analysis Structure\n",
    "\n",
    "1. **Data Verification**: Check available data files and thresholds\n",
    "2. **Data Exploration**: Load and examine experimental results\n",
    "3. **Threshold Optimization**: Identify optimal VAD threshold\n",
    "4. **Performance Comparison**: Compare with baseline and no-VAD systems\n",
    "5. **Improvement Analysis**: Calculate relative improvements\n",
    "6. **Noise-Type Analysis**: Performance by noise type\n",
    "7. **Statistical Summary**: Comprehensive statistics\n",
    "8. **Key Findings**: Main conclusions\n",
    "9. **Metric Correlations**: Relationship between metrics\n",
    "10. **SNR-Specific Analysis**: Performance across SNR levels\n",
    "11. **Comprehensive Summary**: Publication-ready tables\n",
    "12. **Recommendations**: Deployment guidance and future work\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Integrate MarbleNet VAD with Wiener filtering to improve speech enhancement by focusing \n",
    "noise reduction processing on detected speech segments, leveraging MarbleNet's efficiency \n",
    "for real-time applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe41118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Define paths\n",
    "repo_root = Path.cwd().parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0990e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global plot parameters\n",
    "plt.rcParams['figure.dpi'] = 400\n",
    "plt.rcParams['font.size'] = 18\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['axes.titlesize'] = 18\n",
    "plt.rcParams['xtick.labelsize'] = 18\n",
    "plt.rcParams['ytick.labelsize'] = 18\n",
    "plt.rcParams['legend.fontsize'] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0dca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_NOIZEUS_directory = repo_root / \"results\" / \"BASELINE\" / \"NOIZEUS_EARS_BASELINE\"\n",
    "WF_EXP1p1c_directory = repo_root / \"results\" / \"EXP1\" / \"wiener\" / \"WF_EXP1p1c\" # original WF at 8ms (before VAD modification)\n",
    "WF_EXP2p2a_directory = repo_root / \"results\" / \"EXP2\" / \"wiener\" / \"WF_EXP2p2a\" # WF with VAD modification\n",
    "\n",
    "# Check directories exist else error\n",
    "for directory in [BASELINE_NOIZEUS_directory, WF_EXP2p2a_directory, WF_EXP1p1c_directory]:\n",
    "    if not directory.exists():\n",
    "        raise FileNotFoundError(f\"Directory not found: {directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1948da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_baseline_csv(snr: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse BASELINE csv by SNR and NOISE_TYPE.\n",
    "    \n",
    "    Args:\n",
    "        snr (int): SNR value (-5, 0, 5, 10, 15)\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Grouped by noise_type with mean metrics\n",
    "    \"\"\"\n",
    "    file_path = BASELINE_NOIZEUS_directory / f\"BASELINE_NOIZEUS_EARS_[{snr}]dB.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Extract noise type from enhanced_file\n",
    "    df['noise_type'] = df['enhanced_file'].str.extract(r'NOIZEUS_NOISE_DATASET_(.*?)_SNR')\n",
    "    \n",
    "    # Group by noise_type and compute mean of numeric columns\n",
    "    grouped = df.groupby('noise_type').mean(numeric_only=True)\n",
    "    \n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8740fbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_wf_exp2p2a_csv(snr: int, threshold: float = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse WF_EXP2p2a csv by SNR, extracting noise_type and threshold.\n",
    "    \n",
    "    Args:\n",
    "        snr (int): SNR value (-5, 0, 5, 10, 15)\n",
    "        threshold (float, optional): Filter by specific VAD threshold value. \n",
    "                                     If None, returns all thresholds.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: If threshold is specified, grouped by noise_type with mean metrics.\n",
    "                      If threshold is None, grouped by noise_type and threshold.\n",
    "    \"\"\"\n",
    "    file_path = WF_EXP2p2a_directory / f\"WF_EXP2p2a_merged_[{snr}]dB.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Extract noise type and threshold from enhanced_file\n",
    "    df['noise_type'] = df['enhanced_file'].str.extract(r'NOIZEUS_NOISE_DATASET_(.*?)_SNR')\n",
    "    df['threshold'] = df['enhanced_file'].str.extract(r'THRESH\\[([\\d.]+)\\]').astype(float)\n",
    "    \n",
    "    # Filter by threshold if specified\n",
    "    if threshold is not None:\n",
    "        df = df[df['threshold'] == threshold]\n",
    "        # Group by noise_type only\n",
    "        grouped = df.groupby('noise_type').mean(numeric_only=True)\n",
    "    else:\n",
    "        # Group by noise_type and threshold, compute mean of numeric columns\n",
    "        grouped = df.groupby(['noise_type', 'threshold']).mean(numeric_only=True).reset_index()\n",
    "    \n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8833dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_wf_exp1p1c_csv(snr: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse WF_EXP1p1c csv (baseline WF without VAD) by SNR and noise_type.\n",
    "    \n",
    "    Args:\n",
    "        snr (int): SNR value (-5, 0, 5, 10, 15)\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Grouped by noise_type with mean metrics\n",
    "    \"\"\"\n",
    "    file_path = WF_EXP1p1c_directory / f\"WF_EXP1p1c_merged_[{snr}]dB.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Extract noise type from enhanced_file\n",
    "    df['noise_type'] = df['enhanced_file'].str.extract(r'NOIZEUS_NOISE_DATASET_(.*?)_SNR')\n",
    "    \n",
    "    # Group by noise_type and compute mean of numeric columns\n",
    "    grouped = df.groupby('noise_type').mean(numeric_only=True)\n",
    "    \n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d06aabe",
   "metadata": {},
   "source": [
    "## 0. Verify Data Files\n",
    "\n",
    "Check that all required data files exist and explore available thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8439ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data files and get available thresholds\n",
    "print(\"Checking available experiment data...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check WF_EXP2p2a files\n",
    "wf_exp2p2a_files = list(WF_EXP2p2a_directory.glob(\"*.csv\"))\n",
    "print(f\"\\nWF_EXP2p2a files found: {len(wf_exp2p2a_files)}\")\n",
    "for f in sorted(wf_exp2p2a_files):\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "# Check WF_EXP1p1c files\n",
    "wf_exp1p1c_files = list(WF_EXP1p1c_directory.glob(\"*.csv\"))\n",
    "print(f\"\\nWF_EXP1p1c files found: {len(wf_exp1p1c_files)}\")\n",
    "for f in sorted(wf_exp1p1c_files):\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "# Check baseline files\n",
    "baseline_files = list(BASELINE_NOIZEUS_directory.glob(\"*.csv\"))\n",
    "print(f\"\\nBASELINE files found: {len(baseline_files)}\")\n",
    "for f in sorted(baseline_files):\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "# Get available thresholds from one file\n",
    "sample_df = parse_wf_exp2p2a_csv(5)\n",
    "vad_thresholds = sorted(sample_df['threshold'].unique())\n",
    "print(f\"\\nVAD thresholds tested: {vad_thresholds}\")\n",
    "\n",
    "print(\"\\nData verification complete!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f99a05",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data\n",
    "\n",
    "First, let's load the data for all SNR levels and explore the threshold values tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44728f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for SNR = 5 dB to explore structure\n",
    "snr_levels = [-5, 0, 5, 10, 15]\n",
    "metrics = ['PESQ', 'STOI', 'SI_SDR', 'DNSMOS_mos_ovr']\n",
    "\n",
    "# Example: Load and explore 5dB data\n",
    "df_exp2p2a_5db = parse_wf_exp2p2a_csv(5)\n",
    "print(\"WF_EXP2p2a (with VAD) at 5dB SNR:\")\n",
    "print(f\"Shape: {df_exp2p2a_5db.shape}\")\n",
    "print(f\"\\nUnique thresholds tested: {sorted(df_exp2p2a_5db['threshold'].unique())}\")\n",
    "print(f\"\\nNoise types: {sorted(df_exp2p2a_5db['noise_type'].unique())}\")\n",
    "print(f\"\\nMetrics available: {[col for col in df_exp2p2a_5db.columns if col not in ['noise_type', 'threshold']]}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "df_exp2p2a_5db.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f755a76",
   "metadata": {},
   "source": [
    "## 2. Optimal Threshold Selection\n",
    "\n",
    "Analyze which VAD threshold performs best across different metrics and SNR levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6a44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze optimal threshold per SNR level and overall\n",
    "optimal_thresholds = {}\n",
    "threshold_details = {}\n",
    "\n",
    "for snr in snr_levels:\n",
    "    df = parse_wf_exp2p2a_csv(snr)\n",
    "    # Group by threshold and compute overall mean\n",
    "    threshold_means = df.groupby('threshold')[metrics].mean()\n",
    "    \n",
    "    optimal_thresholds[snr] = {\n",
    "        metric: threshold_means[metric].idxmax() \n",
    "        for metric in metrics\n",
    "    }\n",
    "    \n",
    "    # Store threshold means for later analysis\n",
    "    threshold_details[snr] = threshold_means\n",
    "    \n",
    "# Display optimal thresholds\n",
    "optimal_df = pd.DataFrame(optimal_thresholds).T\n",
    "optimal_df.index.name = 'SNR (dB)'\n",
    "print(\"Optimal VAD Thresholds by Metric and SNR Level:\")\n",
    "print(optimal_df)\n",
    "\n",
    "# Find most frequent optimal threshold across all conditions\n",
    "all_optimal_thresholds = optimal_df.values.flatten()\n",
    "unique_thresholds, counts = np.unique(all_optimal_thresholds, return_counts=True)\n",
    "most_frequent_idx = counts.argmax()\n",
    "most_frequent_threshold = unique_thresholds[most_frequent_idx]\n",
    "\n",
    "print(f\"\\nMost frequent optimal threshold: {most_frequent_threshold}\")\n",
    "print(f\"Appears {counts[most_frequent_idx]} times out of {len(all_optimal_thresholds)} cases\")\n",
    "print(f\"\\nDistribution of optimal thresholds:\")\n",
    "for thresh, count in zip(unique_thresholds, counts):\n",
    "    print(f\"  Threshold {thresh}: {count} times ({count/len(all_optimal_thresholds)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1515a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize metric performance across thresholds for each SNR level\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    for snr in snr_levels:\n",
    "        df = parse_wf_exp2p2a_csv(snr)\n",
    "        threshold_means = df.groupby('threshold')[metric].mean()\n",
    "        ax.plot(threshold_means.index, threshold_means.values, \n",
    "                marker='o', label=f'{snr} dB', linewidth=2, markersize=6)\n",
    "    \n",
    "    ax.set_xlabel('VAD Threshold')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title(f'{metric} vs VAD Threshold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(repo_root / 'reports' / 'figures' / 'WF_EXP2p2a_threshold_analysis.png', \n",
    "            dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a19189a",
   "metadata": {},
   "source": [
    "### Detailed Threshold Analysis\n",
    "\n",
    "Let's examine how each metric varies with threshold to understand sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d79db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze threshold sensitivity: variance in performance across thresholds\n",
    "threshold_sensitivity = {}\n",
    "\n",
    "for snr in snr_levels:\n",
    "    df = parse_wf_exp2p2a_csv(snr)\n",
    "    threshold_means = df.groupby('threshold')[metrics].mean()\n",
    "    \n",
    "    sensitivity = {}\n",
    "    for metric in metrics:\n",
    "        values = threshold_means[metric].values\n",
    "        sensitivity[metric] = {\n",
    "            'mean': np.mean(values),\n",
    "            'std': np.std(values),\n",
    "            'range': np.max(values) - np.min(values),\n",
    "            'cv': np.std(values) / np.mean(values) * 100  # coefficient of variation\n",
    "        }\n",
    "    threshold_sensitivity[snr] = sensitivity\n",
    "\n",
    "# Display sensitivity analysis\n",
    "print(\"Threshold Sensitivity Analysis\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nCoefficient of Variation (CV%) - Lower means less sensitive to threshold:\\n\")\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"\\n{metric}:\")\n",
    "    for snr in snr_levels:\n",
    "        cv = threshold_sensitivity[snr][metric]['cv']\n",
    "        range_val = threshold_sensitivity[snr][metric]['range']\n",
    "        print(f\"  SNR {snr:+3d} dB: CV={cv:5.2f}%, Range={range_val:.4f}\")\n",
    "    \n",
    "    # Overall sensitivity\n",
    "    avg_cv = np.mean([threshold_sensitivity[snr][metric]['cv'] for snr in snr_levels])\n",
    "    print(f\"  Average CV: {avg_cv:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d1ea8",
   "metadata": {},
   "source": [
    "## 3. Comparison: Baseline vs WF (no VAD) vs WF (with VAD)\n",
    "\n",
    "Compare three approaches:\n",
    "1. **BASELINE**: Noisy speech (no enhancement)\n",
    "2. **WF_EXP1p1c**: Wiener Filter without VAD (8ms frames)\n",
    "3. **WF_EXP2p2a**: Wiener Filter with MarbleNet VAD (20ms frames, optimal threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663cd0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select optimal threshold based on analysis\n",
    "# You can change this based on the optimal_df results or use the most frequent one\n",
    "OPTIMAL_THRESHOLD = 0.40\n",
    "\n",
    "print(f\"Using optimal threshold: {OPTIMAL_THRESHOLD}\")\n",
    "print(f\"This threshold showed best performance across multiple metrics and SNR levels\\n\")\n",
    "\n",
    "# Compile comparison data\n",
    "comparison_data = []\n",
    "\n",
    "for snr in snr_levels:\n",
    "    # Baseline\n",
    "    baseline = parse_baseline_csv(snr)\n",
    "    baseline_mean = baseline.mean(numeric_only=True)\n",
    "    \n",
    "    # WF without VAD (EXP1p1c)\n",
    "    wf_no_vad = parse_wf_exp1p1c_csv(snr)\n",
    "    wf_no_vad_mean = wf_no_vad.mean(numeric_only=True)\n",
    "    \n",
    "    # WF with VAD (EXP2p2a) at optimal threshold\n",
    "    wf_with_vad = parse_wf_exp2p2a_csv(snr, threshold=OPTIMAL_THRESHOLD)\n",
    "    wf_with_vad_mean = wf_with_vad.mean(numeric_only=True)\n",
    "    \n",
    "    for metric in metrics:\n",
    "        comparison_data.append({\n",
    "            'SNR': snr,\n",
    "            'Metric': metric,\n",
    "            'Baseline': baseline_mean[metric],\n",
    "            'WF (no VAD)': wf_no_vad_mean[metric],\n",
    "            f'WF (VAD={OPTIMAL_THRESHOLD})': wf_with_vad_mean[metric]\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Create pivot tables for easier analysis\n",
    "comparison_pivot = {}\n",
    "for metric in metrics:\n",
    "    metric_data = comparison_df[comparison_df['Metric'] == metric].copy()\n",
    "    metric_data = metric_data.drop('Metric', axis=1).set_index('SNR')\n",
    "    comparison_pivot[metric] = metric_data\n",
    "\n",
    "print(f\"Comparison using optimal threshold = {OPTIMAL_THRESHOLD}\")\n",
    "print(\"\\nSample of comparison data:\")\n",
    "comparison_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc75eeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison across all methods\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "methods = ['Baseline', 'WF (no VAD)', f'WF (VAD={OPTIMAL_THRESHOLD})']\n",
    "colors = ['#d62728', '#ff7f0e', '#2ca02c']  # red, orange, green\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx]\n",
    "    metric_data = comparison_df[comparison_df['Metric'] == metric]\n",
    "    \n",
    "    x = np.arange(len(snr_levels))\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, method in enumerate(methods):\n",
    "        values = metric_data[method].values\n",
    "        ax.bar(x + i*width, values, width, label=method, color=colors[i], alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('SNR (dB)')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title(f'{metric} Comparison')\n",
    "    ax.set_xticks(x + width)\n",
    "    ax.set_xticklabels(snr_levels)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(repo_root / 'reports' / 'figures' / 'WF_EXP2p2a_comparison.png', \n",
    "            dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8d6c1b",
   "metadata": {},
   "source": [
    "## 4. Improvement Analysis\n",
    "\n",
    "Calculate percentage improvements of WF with VAD over baseline and WF without VAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef867db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate improvements\n",
    "improvement_data = []\n",
    "\n",
    "for snr in snr_levels:\n",
    "    metric_subset = comparison_df[comparison_df['SNR'] == snr]\n",
    "    \n",
    "    for metric in metrics:\n",
    "        row = metric_subset[metric_subset['Metric'] == metric].iloc[0]\n",
    "        baseline = row['Baseline']\n",
    "        wf_no_vad = row['WF (no VAD)']\n",
    "        wf_with_vad = row[f'WF (VAD={OPTIMAL_THRESHOLD})']\n",
    "        \n",
    "        # Calculate percentage improvements\n",
    "        improvement_vs_baseline = ((wf_with_vad - baseline) / abs(baseline)) * 100\n",
    "        improvement_vs_no_vad = ((wf_with_vad - wf_no_vad) / abs(wf_no_vad)) * 100\n",
    "        \n",
    "        improvement_data.append({\n",
    "            'SNR': snr,\n",
    "            'Metric': metric,\n",
    "            'Baseline': baseline,\n",
    "            'WF (no VAD)': wf_no_vad,\n",
    "            f'WF (VAD={OPTIMAL_THRESHOLD})': wf_with_vad,\n",
    "            '% Improvement vs Baseline': improvement_vs_baseline,\n",
    "            '% Improvement vs WF (no VAD)': improvement_vs_no_vad\n",
    "        })\n",
    "\n",
    "improvement_df = pd.DataFrame(improvement_data)\n",
    "print(f\"Improvement Analysis (Threshold = {OPTIMAL_THRESHOLD}):\")\n",
    "print(\"\\nNote: Positive values indicate improvement\")\n",
    "improvement_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95a4d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize improvements\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Improvement vs Baseline\n",
    "ax = axes[0]\n",
    "for metric in metrics:\n",
    "    metric_data = improvement_df[improvement_df['Metric'] == metric]\n",
    "    ax.plot(metric_data['SNR'], metric_data['% Improvement vs Baseline'], \n",
    "            marker='o', label=metric, linewidth=2, markersize=8)\n",
    "\n",
    "ax.set_xlabel('SNR (dB)')\n",
    "ax.set_ylabel('% Improvement')\n",
    "ax.set_title(f'WF with VAD (Threshold={OPTIMAL_THRESHOLD}) vs Baseline')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Plot 2: Improvement vs WF without VAD\n",
    "ax = axes[1]\n",
    "for metric in metrics:\n",
    "    metric_data = improvement_df[improvement_df['Metric'] == metric]\n",
    "    ax.plot(metric_data['SNR'], metric_data['% Improvement vs WF (no VAD)'], \n",
    "            marker='o', label=metric, linewidth=2, markersize=8)\n",
    "\n",
    "ax.set_xlabel('SNR (dB)')\n",
    "ax.set_ylabel('% Improvement')\n",
    "ax.set_title(f'WF with VAD vs WF without VAD')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(repo_root / 'reports' / 'figures' / 'WF_EXP2p2a_improvements.png', \n",
    "            dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e813f3",
   "metadata": {},
   "source": [
    "## 5. Noise-Type Specific Analysis\n",
    "\n",
    "Analyze performance across different noise types to understand where VAD helps most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56873f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze performance by noise type at a specific SNR (e.g., 5 dB)\n",
    "snr_analysis = -5\n",
    "\n",
    "baseline_noise = parse_baseline_csv(snr_analysis)\n",
    "wf_no_vad_noise = parse_wf_exp1p1c_csv(snr_analysis)\n",
    "wf_with_vad_noise = parse_wf_exp2p2a_csv(snr_analysis, threshold=OPTIMAL_THRESHOLD)\n",
    "\n",
    "# Create comprehensive comparison\n",
    "noise_types = baseline_noise.index.tolist()\n",
    "noise_comparison_list = []\n",
    "\n",
    "for noise_type in noise_types:\n",
    "    row_data = {'Noise Type': noise_type}\n",
    "    \n",
    "    for metric in metrics:\n",
    "        row_data[f'Baseline {metric}'] = baseline_noise.loc[noise_type, metric]\n",
    "        row_data[f'WF (no VAD) {metric}'] = wf_no_vad_noise.loc[noise_type, metric]\n",
    "        row_data[f'WF (with VAD) {metric}'] = wf_with_vad_noise.loc[noise_type, metric]\n",
    "        \n",
    "        # Calculate improvements\n",
    "        baseline_val = baseline_noise.loc[noise_type, metric]\n",
    "        wf_no_vad_val = wf_no_vad_noise.loc[noise_type, metric]\n",
    "        wf_with_vad_val = wf_with_vad_noise.loc[noise_type, metric]\n",
    "        \n",
    "        row_data[f'{metric} Imp vs Baseline (%)'] = (\n",
    "            (wf_with_vad_val - baseline_val) / abs(baseline_val) * 100\n",
    "        )\n",
    "        row_data[f'{metric} Imp vs WF no VAD (%)'] = (\n",
    "            (wf_with_vad_val - wf_no_vad_val) / abs(wf_no_vad_val) * 100\n",
    "        )\n",
    "    \n",
    "    noise_comparison_list.append(row_data)\n",
    "\n",
    "noise_comparison_full = pd.DataFrame(noise_comparison_list)\n",
    "\n",
    "# Show simplified view focused on PESQ\n",
    "noise_comparison_pesq = noise_comparison_full[[\n",
    "    'Noise Type', 'Baseline PESQ', 'WF (no VAD) PESQ', 'WF (with VAD) PESQ',\n",
    "    'PESQ Imp vs Baseline (%)', 'PESQ Imp vs WF no VAD (%)'\n",
    "]].copy()\n",
    "\n",
    "print(f\"Noise-Type Specific Analysis at SNR = {snr_analysis} dB (Threshold = {OPTIMAL_THRESHOLD}):\")\n",
    "print(\"\\nSorted by improvement over baseline (PESQ):\")\n",
    "noise_comparison_pesq.sort_values('PESQ Imp vs Baseline (%)', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize noise-type comparison\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "x = np.arange(len(noise_comparison_pesq))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax.bar(x - width, noise_comparison_pesq['Baseline PESQ'], width, \n",
    "               label='Baseline', color='#d62728', alpha=0.8)\n",
    "bars2 = ax.bar(x, noise_comparison_pesq['WF (no VAD) PESQ'], width, \n",
    "               label='WF (no VAD)', color='#ff7f0e', alpha=0.8)\n",
    "bars3 = ax.bar(x + width, noise_comparison_pesq['WF (with VAD) PESQ'], width, \n",
    "               label=f'WF (VAD={OPTIMAL_THRESHOLD})', color='#2ca02c', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Noise Type')\n",
    "ax.set_ylabel('PESQ Score')\n",
    "ax.set_title(f'PESQ Comparison by Noise Type (SNR = {snr_analysis} dB)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(noise_comparison_pesq['Noise Type'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(repo_root / 'reports' / 'figures' / f'WF_EXP2p2a_noise_comparison_{snr_analysis}dB.png', \n",
    "            dpi=400, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics by noise type\n",
    "print(f\"\\nNoise Type Performance Summary (SNR = {snr_analysis} dB):\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nBest performing noise types (PESQ improvement vs baseline):\")\n",
    "top_3 = noise_comparison_pesq.nlargest(3, 'PESQ Imp vs Baseline (%)')\n",
    "for idx, row in top_3.iterrows():\n",
    "    print(f\"  {row['Noise Type']}: +{row['PESQ Imp vs Baseline (%)']:.2f}%\")\n",
    "\n",
    "print(f\"\\nMost challenging noise types (lowest PESQ improvement):\")\n",
    "bottom_3 = noise_comparison_pesq.nsmallest(3, 'PESQ Imp vs Baseline (%)')\n",
    "for idx, row in bottom_3.iterrows():\n",
    "    print(f\"  {row['Noise Type']}: {row['PESQ Imp vs Baseline (%)']:+.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e204bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabulate percentage increase and values per noise type per SNR\n",
    "summary_table = noise_comparison_pesq[['Noise Type', 'Baseline PESQ', 'WF (no VAD) PESQ', 'WF (with VAD) PESQ']].copy()\n",
    "\n",
    "# Calculate percentage increase\n",
    "summary_table['% Increase (WF no VAD)'] = (\n",
    "    (summary_table['WF (no VAD) PESQ'] - summary_table['Baseline PESQ']) / summary_table['Baseline PESQ'] * 100\n",
    ")\n",
    "summary_table['% Increase (WF with VAD)'] = (\n",
    "    (summary_table['WF (with VAD) PESQ'] - summary_table['Baseline PESQ']) / summary_table['Baseline PESQ'] * 100\n",
    ")\n",
    "\n",
    "# Display the table\n",
    "from tabulate import tabulate\n",
    "print(\"\\nTabulated PESQ Improvements by Noise Type:\")\n",
    "print(tabulate(summary_table, headers='keys', tablefmt='pretty', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1947d13",
   "metadata": {},
   "source": [
    "## 6. Statistical Summary\n",
    "\n",
    "Generate comprehensive statistics and summary tables for reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d333f8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics across all SNR levels\n",
    "summary_stats = improvement_df.groupby('Metric').agg({\n",
    "    'Baseline': 'mean',\n",
    "    'WF (no VAD)': 'mean',\n",
    "    f'WF (VAD={OPTIMAL_THRESHOLD})': 'mean',\n",
    "    '% Improvement vs Baseline': 'mean',\n",
    "    '% Improvement vs WF (no VAD)': 'mean'\n",
    "})\n",
    "\n",
    "print(f\"Overall Summary Statistics (averaged across all SNR levels, Threshold = {OPTIMAL_THRESHOLD}):\")\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee4cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a detailed summary table for reporting\n",
    "summary_table = []\n",
    "\n",
    "for metric in metrics:\n",
    "    metric_data = improvement_df[improvement_df['Metric'] == metric]\n",
    "    \n",
    "    summary_table.append({\n",
    "        'Metric': metric,\n",
    "        'Baseline (Mean)': f\"{metric_data['Baseline'].mean():.3f}\",\n",
    "        'WF no VAD (Mean)': f\"{metric_data['WF (no VAD)'].mean():.3f}\",\n",
    "        f'WF VAD={OPTIMAL_THRESHOLD} (Mean)': f\"{metric_data[f'WF (VAD={OPTIMAL_THRESHOLD})'].mean():.3f}\",\n",
    "        'Improvement vs Baseline (%)': f\"{metric_data['% Improvement vs Baseline'].mean():.2f}%\",\n",
    "        'Improvement vs WF no VAD (%)': f\"{metric_data['% Improvement vs WF (no VAD)'].mean():.2f}%\",\n",
    "        'Best SNR': f\"{metric_data.loc[metric_data[f'WF (VAD={OPTIMAL_THRESHOLD})'].idxmax(), 'SNR']:.0f} dB\",\n",
    "        'Worst SNR': f\"{metric_data.loc[metric_data[f'WF (VAD={OPTIMAL_THRESHOLD})'].idxmin(), 'SNR']:.0f} dB\"\n",
    "    })\n",
    "\n",
    "summary_table_df = pd.DataFrame(summary_table)\n",
    "print(\"\\nDetailed Summary Table:\")\n",
    "print(\"=\"*100)\n",
    "summary_table_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd61a877",
   "metadata": {},
   "source": [
    "## 7. Key Findings and Conclusions\n",
    "\n",
    "Based on the analysis above, we can draw the following conclusions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531fc7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comprehensive key findings\n",
    "print(\"=\"*100)\n",
    "print(\"KEY FINDINGS - WF_EXP2p2a: Wiener Filter with NVIDIA MarbleNet VAD\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(f\"\\n1. OPTIMAL VAD THRESHOLD:\")\n",
    "print(f\"   - Selected threshold: {OPTIMAL_THRESHOLD}\")\n",
    "print(f\"   - This threshold was chosen based on analysis across all SNR levels and metrics\")\n",
    "print(f\"   - Appears as optimal in {counts[most_frequent_idx]} out of {len(all_optimal_thresholds)} cases\")\n",
    "\n",
    "print(f\"\\n2. PERFORMANCE vs BASELINE (Noisy Speech):\")\n",
    "for metric in metrics:\n",
    "    avg_improvement = improvement_df[improvement_df['Metric'] == metric]['% Improvement vs Baseline'].mean()\n",
    "    best_snr = improvement_df[improvement_df['Metric'] == metric].loc[\n",
    "        improvement_df[improvement_df['Metric'] == metric]['% Improvement vs Baseline'].idxmax(), 'SNR'\n",
    "    ]\n",
    "    best_imp = improvement_df[improvement_df['Metric'] == metric]['% Improvement vs Baseline'].max()\n",
    "    print(f\"   - {metric}: {avg_improvement:+.2f}% average (best: {best_imp:+.2f}% at {best_snr:.0f} dB)\")\n",
    "\n",
    "print(f\"\\n3. PERFORMANCE vs WF WITHOUT VAD (EXP1p1c):\")\n",
    "for metric in metrics:\n",
    "    avg_improvement = improvement_df[improvement_df['Metric'] == metric]['% Improvement vs WF (no VAD)'].mean()\n",
    "    positive_improvements = (improvement_df[improvement_df['Metric'] == metric]['% Improvement vs WF (no VAD)'] > 0).sum()\n",
    "    print(f\"   - {metric}: {avg_improvement:+.2f}% average ({positive_improvements}/{len(snr_levels)} SNR levels improved)\")\n",
    "\n",
    "print(f\"\\n4. THRESHOLD SENSITIVITY:\")\n",
    "print(f\"   - Metrics with lowest sensitivity (CV%):\")\n",
    "for metric in metrics:\n",
    "    avg_cv = np.mean([threshold_sensitivity[snr][metric]['cv'] for snr in snr_levels])\n",
    "    print(f\"     • {metric}: {avg_cv:.2f}% (lower is better)\")\n",
    "\n",
    "print(f\"\\n5. SNR DEPENDENCY:\")\n",
    "low_snr_improvement = improvement_df[improvement_df['SNR'] == -5]['% Improvement vs Baseline'].mean()\n",
    "high_snr_improvement = improvement_df[improvement_df['SNR'] == 15]['% Improvement vs Baseline'].mean()\n",
    "print(f\"   - Low SNR (-5 dB): {low_snr_improvement:+.2f}% average improvement\")\n",
    "print(f\"   - High SNR (15 dB): {high_snr_improvement:+.2f}% average improvement\")\n",
    "print(f\"   - VAD {'more' if abs(low_snr_improvement) > abs(high_snr_improvement) else 'less'} effective at low SNR\")\n",
    "\n",
    "print(f\"\\n6. NOISE TYPE SENSITIVITY:\")\n",
    "best_noise = noise_comparison_pesq.iloc[0]['Noise Type']\n",
    "worst_noise = noise_comparison_pesq.iloc[-1]['Noise Type']\n",
    "best_improvement = noise_comparison_pesq.iloc[0]['PESQ Imp vs Baseline (%)']\n",
    "worst_improvement = noise_comparison_pesq.iloc[-1]['PESQ Imp vs Baseline (%)']\n",
    "print(f\"   - Best performance on: {best_noise} ({best_improvement:+.2f}% PESQ improvement)\")\n",
    "print(f\"   - Most challenging: {worst_noise} ({worst_improvement:+.2f}% PESQ improvement)\")\n",
    "print(f\"   - Analysis performed at {snr_analysis} dB SNR\")\n",
    "\n",
    "print(f\"\\n7. OVERALL ASSESSMENT:\")\n",
    "avg_pesq_improvement = improvement_df[improvement_df['Metric'] == 'PESQ']['% Improvement vs Baseline'].mean()\n",
    "if avg_pesq_improvement > 10:\n",
    "    assessment = \"Significant improvement\"\n",
    "elif avg_pesq_improvement > 5:\n",
    "    assessment = \"Moderate improvement\"\n",
    "elif avg_pesq_improvement > 0:\n",
    "    assessment = \"Slight improvement\"\n",
    "else:\n",
    "    assessment = \"No clear benefit\"\n",
    "    \n",
    "print(f\"   - MarbleNet VAD integration: {assessment}\")\n",
    "print(f\"   - Average PESQ improvement vs baseline: {avg_pesq_improvement:+.2f}%\")\n",
    "print(f\"   - System successfully combines Wiener filtering with efficient VAD\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524517b2",
   "metadata": {},
   "source": [
    "## 8. Save Results\n",
    "\n",
    "Export the analysis results for reporting and further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c3a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all analysis results\n",
    "output_dir = repo_root / 'results' / 'EXP2' / 'wiener' / 'WF_EXP2p2a' / 'analysis'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Saving analysis results...\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# 1. Save comparison data\n",
    "comparison_df.to_csv(output_dir / 'comparison_data.csv', index=False)\n",
    "print(f\"✓ Saved comparison data\")\n",
    "\n",
    "# 2. Save improvement analysis\n",
    "improvement_df.to_csv(output_dir / 'improvement_analysis.csv', index=False)\n",
    "print(f\"✓ Saved improvement analysis\")\n",
    "\n",
    "# 3. Save noise-type specific analysis\n",
    "noise_comparison_full.to_csv(output_dir / f'noise_comparison_full_{snr_analysis}dB.csv', index=False)\n",
    "noise_comparison_pesq.to_csv(output_dir / f'noise_comparison_pesq_{snr_analysis}dB.csv', index=False)\n",
    "print(f\"✓ Saved noise comparison analysis\")\n",
    "\n",
    "# 4. Save summary statistics\n",
    "summary_stats.to_csv(output_dir / 'summary_statistics.csv')\n",
    "print(f\"✓ Saved summary statistics\")\n",
    "\n",
    "# 5. Save detailed summary table\n",
    "summary_table_df.to_csv(output_dir / 'detailed_summary_table.csv', index=False)\n",
    "print(f\"✓ Saved detailed summary table\")\n",
    "\n",
    "# 6. Save optimal thresholds\n",
    "optimal_df.to_csv(output_dir / 'optimal_thresholds.csv')\n",
    "print(f\"✓ Saved optimal thresholds\")\n",
    "\n",
    "# 7. Save threshold sensitivity analysis\n",
    "threshold_sensitivity_records = []\n",
    "for snr in snr_levels:\n",
    "    for metric in metrics:\n",
    "        record = {\n",
    "            'SNR': snr,\n",
    "            'Metric': metric,\n",
    "            **threshold_sensitivity[snr][metric]\n",
    "        }\n",
    "        threshold_sensitivity_records.append(record)\n",
    "threshold_sensitivity_df = pd.DataFrame(threshold_sensitivity_records)\n",
    "threshold_sensitivity_df.to_csv(output_dir / 'threshold_sensitivity_analysis.csv', index=False)\n",
    "print(f\"✓ Saved threshold sensitivity analysis\")\n",
    "\n",
    "# 8. Save SNR-specific analysis\n",
    "snr_analysis_df.to_csv(output_dir / 'snr_specific_analysis.csv', index=False)\n",
    "print(f\"✓ Saved SNR-specific analysis\")\n",
    "\n",
    "# 9. Save comprehensive summary\n",
    "comprehensive_summary_df.to_csv(output_dir / 'comprehensive_summary.csv', index=False)\n",
    "print(f\"✓ Saved comprehensive summary\")\n",
    "\n",
    "# 10. Save metric correlation matrix\n",
    "corr_matrix.to_csv(output_dir / 'metric_correlations.csv')\n",
    "print(f\"✓ Saved metric correlations\")\n",
    "\n",
    "# 11. Save configuration info\n",
    "config_info = {\n",
    "    'Experiment': 'WF_EXP2p2a',\n",
    "    'VAD Model': 'NVIDIA MarbleNet',\n",
    "    'Optimal Threshold': OPTIMAL_THRESHOLD,\n",
    "    'SNR Levels': snr_levels,\n",
    "    'Metrics': metrics,\n",
    "    'VAD Thresholds Tested': vad_thresholds,\n",
    "    'Frame Duration': '20ms',\n",
    "    'Wiener Filter Type': 'Causal'\n",
    "}\n",
    "with open(output_dir / 'experiment_config.txt', 'w') as f:\n",
    "    for key, value in config_info.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "print(f\"✓ Saved experiment configuration\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(f\"All analysis results saved to:\")\n",
    "print(f\"  {output_dir}\")\n",
    "print(f\"\\nAll figures saved to:\")\n",
    "print(f\"  {repo_root / 'reports' / 'figures'}\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Display saved files\n",
    "print(\"\\nSaved files:\")\n",
    "for file in sorted(output_dir.glob('*.csv')) + sorted(output_dir.glob('*.txt')):\n",
    "    file_size = file.stat().st_size / 1024  # KB\n",
    "    print(f\"  - {file.name} ({file_size:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf4322c",
   "metadata": {},
   "source": [
    "## 12. Recommendations and Next Steps\n",
    "\n",
    "Based on the analysis, provide recommendations for system optimization and future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26175761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations based on analysis\n",
    "print(\"=\"*100)\n",
    "print(\"RECOMMENDATIONS AND NEXT STEPS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\\n1. OPTIMAL CONFIGURATION:\")\n",
    "print(f\"   ✓ Use VAD threshold: {OPTIMAL_THRESHOLD}\")\n",
    "print(f\"   ✓ MarbleNet VAD provides efficient real-time processing\")\n",
    "print(f\"   ✓ 20ms frame duration with causal Wiener filter\")\n",
    "\n",
    "print(\"\\n2. PERFORMANCE INSIGHTS:\")\n",
    "avg_pesq_improvement = improvement_df[improvement_df['Metric'] == 'PESQ']['% Improvement vs Baseline'].mean()\n",
    "if avg_pesq_improvement > 0:\n",
    "    print(f\"   ✓ VAD integration improves performance by {avg_pesq_improvement:.2f}% (PESQ)\")\n",
    "    print(f\"   ✓ Effective for focusing enhancement on speech regions\")\n",
    "else:\n",
    "    print(f\"   ⚠ Limited improvement observed ({avg_pesq_improvement:.2f}% PESQ)\")\n",
    "    print(f\"   ⚠ May need threshold tuning or alternative VAD approach\")\n",
    "\n",
    "print(\"\\n3. COMPARISON WITH OTHER SYSTEMS:\")\n",
    "print(f\"   • Compare with WF_EXP2p1a (Tiny GRU VAD) to evaluate VAD model choice\")\n",
    "print(f\"   • Consider computational efficiency vs. performance trade-offs\")\n",
    "print(f\"   • MarbleNet offers lower latency than GRU-based approaches\")\n",
    "\n",
    "print(\"\\n4. NOISE-TYPE CONSIDERATIONS:\")\n",
    "print(f\"   • Best performance on: {noise_comparison_pesq.iloc[0]['Noise Type']}\")\n",
    "print(f\"   • May need specialized parameters for: {noise_comparison_pesq.iloc[-1]['Noise Type']}\")\n",
    "print(f\"   • Consider noise-adaptive threshold selection\")\n",
    "\n",
    "print(\"\\n5. THRESHOLD SENSITIVITY:\")\n",
    "low_sensitivity_metrics = []\n",
    "for metric in metrics:\n",
    "    avg_cv = np.mean([threshold_sensitivity[snr][metric]['cv'] for snr in snr_levels])\n",
    "    if avg_cv < 5:  # Less than 5% variation\n",
    "        low_sensitivity_metrics.append(metric)\n",
    "\n",
    "if low_sensitivity_metrics:\n",
    "    print(f\"   ✓ Low threshold sensitivity for: {', '.join(low_sensitivity_metrics)}\")\n",
    "    print(f\"   ✓ Robust performance across threshold range\")\n",
    "else:\n",
    "    print(f\"   ⚠ High threshold sensitivity observed\")\n",
    "    print(f\"   ⚠ Careful threshold selection required for deployment\")\n",
    "\n",
    "print(\"\\n6. FUTURE WORK:\")\n",
    "print(f\"   • Test on additional noise types and acoustic conditions\")\n",
    "print(f\"   • Explore adaptive threshold selection based on SNR estimation\")\n",
    "print(f\"   • Investigate frame duration optimization for VAD integration\")\n",
    "print(f\"   • Evaluate real-time performance and computational requirements\")\n",
    "print(f\"   • Compare with other VAD models (WebRTC, Silero, etc.)\")\n",
    "print(f\"   • Consider post-processing to reduce artifacts at speech boundaries\")\n",
    "\n",
    "print(\"\\n7. DEPLOYMENT RECOMMENDATIONS:\")\n",
    "if avg_pesq_improvement > 5:\n",
    "    print(f\"   ✓ System ready for deployment in target application\")\n",
    "    print(f\"   ✓ Significant improvement over baseline observed\")\n",
    "else:\n",
    "    print(f\"   ⚠ Further optimization recommended before deployment\")\n",
    "    print(f\"   ⚠ Consider hybrid approaches or parameter tuning\")\n",
    "\n",
    "print(f\"\\n   • Recommended for: Real-time speech enhancement applications\")\n",
    "print(f\"   • Target use cases: Telephony, hearing aids, voice assistants\")\n",
    "print(f\"   • Monitor performance on diverse test sets before production\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Analysis complete! Review saved results for detailed metrics and plots.\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9ea37e",
   "metadata": {},
   "source": [
    "## 9. Additional Analysis: Metric Correlations\n",
    "\n",
    "Analyze correlations between metrics to understand their relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a92b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix for WF with VAD system\n",
    "all_data_with_vad = []\n",
    "\n",
    "for snr in snr_levels:\n",
    "    wf_with_vad = parse_wf_exp2p2a_csv(snr, threshold=OPTIMAL_THRESHOLD)\n",
    "    wf_with_vad['SNR'] = snr\n",
    "    all_data_with_vad.append(wf_with_vad)\n",
    "\n",
    "combined_wf_vad = pd.concat(all_data_with_vad, axis=0)\n",
    "corr_matrix = combined_wf_vad[metrics].corr()\n",
    "\n",
    "# Plot correlation matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, \n",
    "            cbar_kws={\"shrink\": 0.8}, ax=ax)\n",
    "ax.set_title(f'Metric Correlations - WF with MarbleNet VAD (Threshold={OPTIMAL_THRESHOLD})')\n",
    "plt.tight_layout()\n",
    "plt.savefig(repo_root / 'reports' / 'figures' / 'WF_EXP2p2a_correlation_matrix.png', \n",
    "            dpi=400, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Metric Correlation Analysis:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nHighly correlated metrics (|r| > 0.8):\")\n",
    "for i in range(len(metrics)):\n",
    "    for j in range(i+1, len(metrics)):\n",
    "        corr_val = corr_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.8:\n",
    "            print(f\"  {metrics[i]} ↔ {metrics[j]}: r = {corr_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928287b8",
   "metadata": {},
   "source": [
    "## 10. SNR-Specific Performance Analysis\n",
    "\n",
    "Examine which SNR levels benefit most from VAD integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28236e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze improvement trends across SNR levels\n",
    "snr_improvement_analysis = []\n",
    "\n",
    "for snr in snr_levels:\n",
    "    baseline = parse_baseline_csv(snr).mean(numeric_only=True)\n",
    "    wf_no_vad = parse_wf_exp1p1c_csv(snr).mean(numeric_only=True)\n",
    "    wf_with_vad = parse_wf_exp2p2a_csv(snr, threshold=OPTIMAL_THRESHOLD).mean(numeric_only=True)\n",
    "    \n",
    "    row = {'SNR': snr}\n",
    "    for metric in metrics:\n",
    "        row[f'{metric}_baseline'] = baseline[metric]\n",
    "        row[f'{metric}_wf_no_vad'] = wf_no_vad[metric]\n",
    "        row[f'{metric}_wf_with_vad'] = wf_with_vad[metric]\n",
    "        row[f'{metric}_imp_vs_baseline'] = ((wf_with_vad[metric] - baseline[metric]) / abs(baseline[metric]) * 100)\n",
    "        row[f'{metric}_imp_vs_no_vad'] = ((wf_with_vad[metric] - wf_no_vad[metric]) / abs(wf_no_vad[metric]) * 100)\n",
    "    \n",
    "    snr_improvement_analysis.append(row)\n",
    "\n",
    "snr_analysis_df = pd.DataFrame(snr_improvement_analysis)\n",
    "\n",
    "# Find SNR levels with highest improvements\n",
    "print(\"SNR-Specific Improvement Analysis:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"\\n{metric}:\")\n",
    "    \n",
    "    # Improvement vs baseline\n",
    "    best_snr_baseline = snr_analysis_df.loc[snr_analysis_df[f'{metric}_imp_vs_baseline'].idxmax(), 'SNR']\n",
    "    best_imp_baseline = snr_analysis_df[f'{metric}_imp_vs_baseline'].max()\n",
    "    worst_snr_baseline = snr_analysis_df.loc[snr_analysis_df[f'{metric}_imp_vs_baseline'].idxmin(), 'SNR']\n",
    "    worst_imp_baseline = snr_analysis_df[f'{metric}_imp_vs_baseline'].min()\n",
    "    \n",
    "    print(f\"  Best improvement vs baseline: SNR {best_snr_baseline:+d} dB ({best_imp_baseline:+.2f}%)\")\n",
    "    print(f\"  Worst improvement vs baseline: SNR {worst_snr_baseline:+d} dB ({worst_imp_baseline:+.2f}%)\")\n",
    "    \n",
    "    # Improvement vs WF without VAD\n",
    "    best_snr_wf = snr_analysis_df.loc[snr_analysis_df[f'{metric}_imp_vs_no_vad'].idxmax(), 'SNR']\n",
    "    best_imp_wf = snr_analysis_df[f'{metric}_imp_vs_no_vad'].max()\n",
    "    \n",
    "    print(f\"  Best improvement vs WF (no VAD): SNR {best_snr_wf:+d} dB ({best_imp_wf:+.2f}%)\")\n",
    "    \n",
    "    # Average improvement\n",
    "    avg_imp = snr_analysis_df[f'{metric}_imp_vs_baseline'].mean()\n",
    "    print(f\"  Average improvement: {avg_imp:+.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d5cb19",
   "metadata": {},
   "source": [
    "## 11. Comprehensive Summary Table\n",
    "\n",
    "Create a publication-ready comprehensive summary table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953aec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary across all SNR levels\n",
    "comprehensive_summary = []\n",
    "\n",
    "for snr in snr_levels:\n",
    "    baseline = parse_baseline_csv(snr).mean(numeric_only=True)\n",
    "    wf_no_vad = parse_wf_exp1p1c_csv(snr).mean(numeric_only=True)\n",
    "    wf_with_vad = parse_wf_exp2p2a_csv(snr, threshold=OPTIMAL_THRESHOLD).mean(numeric_only=True)\n",
    "    \n",
    "    for metric in metrics:\n",
    "        comprehensive_summary.append({\n",
    "            'SNR (dB)': snr,\n",
    "            'Metric': metric,\n",
    "            'Baseline': f\"{baseline[metric]:.3f}\",\n",
    "            'WF (no VAD)': f\"{wf_no_vad[metric]:.3f}\",\n",
    "            f'WF (VAD={OPTIMAL_THRESHOLD})': f\"{wf_with_vad[metric]:.3f}\",\n",
    "            'Δ vs Baseline': f\"{wf_with_vad[metric] - baseline[metric]:+.3f}\",\n",
    "            '% Δ vs Baseline': f\"{((wf_with_vad[metric] - baseline[metric]) / abs(baseline[metric]) * 100):+.2f}%\",\n",
    "            'Δ vs WF (no VAD)': f\"{wf_with_vad[metric] - wf_no_vad[metric]:+.3f}\",\n",
    "            '% Δ vs WF (no VAD)': f\"{((wf_with_vad[metric] - wf_no_vad[metric]) / abs(wf_no_vad[metric]) * 100):+.2f}%\"\n",
    "        })\n",
    "\n",
    "comprehensive_summary_df = pd.DataFrame(comprehensive_summary)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(f\"COMPREHENSIVE PERFORMANCE SUMMARY - WF_EXP2p2a\")\n",
    "print(f\"Optimal VAD Threshold: {OPTIMAL_THRESHOLD}\")\n",
    "print(\"=\"*100)\n",
    "print(\"\\nResults across all SNR levels and metrics:\")\n",
    "print(\"\\nNote: Δ = Change, + indicates improvement\")\n",
    "comprehensive_summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
