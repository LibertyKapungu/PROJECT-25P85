{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d844cba8",
   "metadata": {},
   "source": [
    "# GTCRN + Wiener Filter (EXP3p2a) Analysis\n",
    "\n",
    "This notebook reviews the GTCRNWF EXP3p2a experiments that append causal Wiener filtering to the GTCRN neural enhancer. We focus on how frame length (8/20/25 ms) and the Wiener strength parameter `mu` (intelligibility, balanced, quality settings) impact objective metrics across the DNS challenge test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b9b68a",
   "metadata": {},
   "source": [
    "## Experiment Catalogue\n",
    "- **Noisy Baseline:** Raw noisy mixtures (no enhancement).\n",
    "- **GTCRN (No WF):** Baseline neural enhancer without post-processing.\n",
    "- **GTCRN+WF 8 ms:** `mu` tuned for intelligibility (0.123), balanced (0.552), and quality (0.980).\n",
    "- **GTCRN+WF 20 ms:** Larger analysis window; `mu` values 0.374, 0.677, 0.980.\n",
    "- **GTCRN+WF 25 ms:** Longest frame; `mu` values 0.374, 0.677, 0.980.\n",
    "- Metrics tracked per SNR (`-5` to `15` dB): PESQ, STOI, SI-SDR, DNSMOS overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b07af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "import re\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "# Configure paths\n",
    "repo_root = Path.cwd().parent.parent\n",
    "results_root = repo_root / \"results\" / \"EXP3\" / \"GTCRN\"\n",
    "figures_dir = repo_root / \"reports\" / \"figures\" / \"GTCRNWF_EXP3p2a\"\n",
    "figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "snr_levels = [-5, 0, 5, 10, 15]\n",
    "metrics_of_interest = [\"PESQ\", \"STOI\", \"SI_SDR\", \"DNSMOS_p808_mos\"]\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams.update({\n",
    "    \"figure.dpi\": 300,\n",
    "    \"font.size\": 14,\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"axes.titlesize\": 16,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"legend.fontsize\": 12,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb437ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = {\n",
    "    \"BASELINE_NOIZEUS_EARS\": {\n",
    "        \"label\": \"Noisy Baseline\",\n",
    "        \"frame_ms\": None,\n",
    "        \"mu\": None,\n",
    "        \"focus\": \"No Enhancement\",\n",
    "        \"directory\": repo_root / \"results\" / \"BASELINE\" / \"NOIZEUS_EARS_BASELINE\",\n",
    "        \"template\": \"BASELINE_NOIZEUS_EARS_[{snr}]dB.csv\",\n",
    "    },\n",
    "    \"GTCRN_EXP3p2a\": {\n",
    "        \"label\": \"GTCRN (No WF)\",\n",
    "        \"frame_ms\": None,\n",
    "        \"mu\": None,\n",
    "        \"focus\": \"Neural\",\n",
    "        \"directory\": results_root / \"GTCRN_EXP3p2a\",\n",
    "        \"template\": \"GTCRN_EXP3p2a_merged_[{snr}]dB.csv\",\n",
    "    },\n",
    "    \"GTCRNWF_EXP3p2a_8ms_intelligibility\": {\n",
    "        \"label\": \"GTCRN+WF 8ms Intelligibility (mu=0.123)\",\n",
    "        \"frame_ms\": 8,\n",
    "        \"mu\": 0.123,\n",
    "        \"focus\": \"Intelligibility\",\n",
    "        \"directory\": results_root / \"GTCRNWF_EXP3p2a_8ms_intelligibility\",\n",
    "        \"template\": \"GTCRNWF_EXP3p2a_8ms_intelligibility_merged_[{snr}]dB.csv\",\n",
    "    },\n",
    "    \"GTCRNWF_EXP3p2a_8ms_balance\": {\n",
    "        \"label\": \"GTCRN+WF 8ms Balanced (mu=0.552)\",\n",
    "        \"frame_ms\": 8,\n",
    "        \"mu\": 0.552,\n",
    "        \"focus\": \"Balanced\",\n",
    "        \"directory\": results_root / \"GTCRNWF_EXP3p2a_8ms_balance\",\n",
    "        \"template\": \"GTCRNWF_EXP3p2a_8ms_balance_merged_[{snr}]dB.csv\",\n",
    "    },\n",
    "    \"GTCRNWF_EXP3p2a_8ms_quality\": {\n",
    "        \"label\": \"GTCRN+WF 8ms Quality (mu=0.980)\",\n",
    "        \"frame_ms\": 8,\n",
    "        \"mu\": 0.98,\n",
    "        \"focus\": \"Quality\",\n",
    "        \"directory\": results_root / \"GTCRNWF_EXP3p2a_8ms_quality\",\n",
    "        \"template\": \"GTCRNWF_EXP3p2a_8ms_quality_merged_[{snr}]dB.csv\",\n",
    "    },\n",
    "    \"GTCRNWF_EXP3p2a_20ms_intelligibility\": {\n",
    "        \"label\": \"GTCRN+WF 20ms Intelligibility (mu=0.374)\",\n",
    "        \"frame_ms\": 20,\n",
    "        \"mu\": 0.374,\n",
    "        \"focus\": \"Intelligibility\",\n",
    "        \"directory\": results_root / \"GTCRNWF_EXP3p2a_20ms_intelligibility\",\n",
    "        \"template\": \"GTCRNWF_EXP3p2a_20ms_intelligibility_merged_[{snr}]dB.csv\",\n",
    "    },\n",
    "    \"GTCRNWF_EXP3p2a_20ms_balance\": {\n",
    "        \"label\": \"GTCRN+WF 20ms Balanced (mu=0.677)\",\n",
    "        \"frame_ms\": 20,\n",
    "        \"mu\": 0.677,\n",
    "        \"focus\": \"Balanced\",\n",
    "        \"directory\": results_root / \"GTCRNWF_EXP3p2a_20ms_balance\",\n",
    "        \"template\": \"GTCRNWF_EXP3p2a_20ms_balance_merged_[{snr}]dB.csv\",\n",
    "    },\n",
    "    \"GTCRNWF_EXP3p2a_20ms_quality\": {\n",
    "        \"label\": \"GTCRN+WF 20ms Quality (mu=0.980)\",\n",
    "        \"frame_ms\": 20,\n",
    "        \"mu\": 0.98,\n",
    "        \"focus\": \"Quality\",\n",
    "        \"directory\": results_root / \"GTCRNWF_EXP3p2a_20ms_quality\",\n",
    "        \"template\": \"GTCRNWF_EXP3p2a_20ms_quality_merged_[{snr}]dB.csv\",\n",
    "    },\n",
    "    \"GTCRNWF_EXP3p2a_25ms_intelligibility\": {\n",
    "        \"label\": \"GTCRN+WF 25ms Intelligibility (mu=0.374)\",\n",
    "        \"frame_ms\": 25,\n",
    "        \"mu\": 0.374,\n",
    "        \"focus\": \"Intelligibility\",\n",
    "        \"directory\": results_root / \"GTCRNWF_EXP3p2a_25ms_intelligibility\",\n",
    "        \"template\": \"GTCRNWF_EXP3p2a_25ms_intelligibility_merged_[{snr}]dB.csv\",\n",
    "    },\n",
    "    \"GTCRNWF_EXP3p2a_25ms_balance\": {\n",
    "        \"label\": \"GTCRN+WF 25ms Balanced (mu=0.677)\",\n",
    "        \"frame_ms\": 25,\n",
    "        \"mu\": 0.677,\n",
    "        \"focus\": \"Balanced\",\n",
    "        \"directory\": results_root / \"GTCRNWF_EXP3p2a_25ms_balance\",\n",
    "        \"template\": \"GTCRNWF_EXP3p2a_25ms_balance_merged_[{snr}]dB.csv\",\n",
    "    },\n",
    "    \"GTCRNWF_EXP3p2a_25ms_quality\": {\n",
    "        \"label\": \"GTCRN+WF 25ms Quality (mu=0.980)\",\n",
    "        \"frame_ms\": 25,\n",
    "        \"mu\": 0.98,\n",
    "        \"focus\": \"Quality\",\n",
    "        \"directory\": results_root / \"GTCRNWF_EXP3p2a_25ms_quality\",\n",
    "        \"template\": \"GTCRNWF_EXP3p2a_25ms_quality_merged_[{snr}]dB.csv\",\n",
    "    },\n",
    "    \"WF_EXP1p1d\": {\n",
    "        \"label\": \"WF 25ms Default (mu=0.98)\",\n",
    "        \"frame_ms\": 25,\n",
    "        \"mu\": 0.98,\n",
    "        \"focus\": \"Default\",\n",
    "        \"directory\": repo_root / \"results\" / \"EXP1\" / \"wiener\" / \"WF_EXP1p1d\",\n",
    "        \"template\": \"WF_EXP1p1d_merged_[{snr}]dB.csv\",\n",
    "    },\n",
    "}\n",
    "\n",
    "meta_fields = [\"label\", \"frame_ms\", \"mu\", \"focus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b045e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment(prefix: str, meta: dict) -> pd.DataFrame:\n",
    "    \"\"\"Load merged CSV files for a given experiment across all SNR levels.\"\"\"\n",
    "    frames = []\n",
    "    directory = meta[\"directory\"]\n",
    "    template = meta[\"template\"]\n",
    "    for snr in snr_levels:\n",
    "        csv_path = directory / template.format(snr=snr)\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df['SNR'] = snr\n",
    "        df['experiment'] = prefix\n",
    "        frames.append(df)\n",
    "    result = pd.concat(frames, ignore_index=True)\n",
    "    if 'enhanced_file' in result.columns:\n",
    "        result['noise_type'] = result['enhanced_file'].str.extract(r'NOIZEUS_NOISE_DATASET_(.*?)_SNR')\n",
    "    else:\n",
    "        result['noise_type'] = np.nan\n",
    "    return result\n",
    "\n",
    "\n",
    "def build_summary_tables() -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Return full concatenated data and SNR-aggregated summary tables.\"\"\"\n",
    "    all_frames = []\n",
    "    summaries = []\n",
    "    for exp_name, meta in catalog.items():\n",
    "        df = load_experiment(exp_name, meta)\n",
    "        for field in meta_fields:\n",
    "            df[field] = meta.get(field)\n",
    "        all_frames.append(df)\n",
    "\n",
    "        summary = df.groupby('SNR')[metrics_of_interest].mean().reset_index()\n",
    "        summary['experiment'] = exp_name\n",
    "        for field in meta_fields:\n",
    "            summary[field] = meta.get(field)\n",
    "        summaries.append(summary)\n",
    "    full_df = pd.concat(all_frames, ignore_index=True)\n",
    "    summary_df = pd.concat(summaries, ignore_index=True)\n",
    "    return full_df, summary_df\n",
    "\n",
    "\n",
    "full_results, summary_by_snr = build_summary_tables()\n",
    "summary_by_snr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbc47b1",
   "metadata": {},
   "source": [
    "## Check Loaded Data\n",
    "The next cell concatenates all metrics from the experiment CSVs and confirms the expected schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae15098b",
   "metadata": {},
   "source": [
    "## Overall SNR-Averaged Performance\n",
    "We compute the mean of each metric across all SNRs for each configuration to establish a high-level ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a504dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_lookup = pd.DataFrame({\n",
    "    key: {field: catalog[key].get(field) for field in meta_fields}\n",
    "    for key in catalog\n",
    "}).T\n",
    "\n",
    "overall_mean = (\n",
    "    summary_by_snr.groupby('experiment')[metrics_of_interest].mean()\n",
    "    .join(meta_lookup)\n",
    "    .reset_index()\n",
    "    .rename(columns={'DNSMOS_p808_mos': 'DNSMOS'})\n",
    ")\n",
    "overall_mean.sort_values('DNSMOS', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e071104",
   "metadata": {},
   "source": [
    "## Percentage Gains vs Reference Systems\n",
    "Tables below summarise the mean percentage change in each metric relative to (a) the noisy baseline mixtures and (b) the GTCRN output. Positive values mean the row configuration improves upon the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da41597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_percentage_gain(reference_key: str) -> pd.DataFrame:\n",
    "    \"\"\"Return mean percentage gain over a reference experiment for all metrics.\"\"\"\n",
    "    reference = summary_by_snr[summary_by_snr['experiment'] == reference_key]\n",
    "    rows = []\n",
    "    for exp_name in catalog:\n",
    "        if exp_name == reference_key:\n",
    "            continue\n",
    "        exp_slice = summary_by_snr[summary_by_snr['experiment'] == exp_name]\n",
    "        merged = exp_slice.merge(reference, on='SNR', suffixes=('', '_ref'))\n",
    "        for metric in metrics_of_interest:\n",
    "            delta = merged[metric] - merged[f\"{metric}_ref\"]\n",
    "            pct = (delta / merged[f\"{metric}_ref\"]) * 100\n",
    "            rows.append({\n",
    "                'experiment': exp_name,\n",
    "                'metric': metric,\n",
    "                'avg_pct': pct.mean(),\n",
    "            })\n",
    "    pivot = pd.DataFrame(rows).pivot(index='experiment', columns='metric', values='avg_pct')\n",
    "    pivot = pivot.rename(columns={'DNSMOS_p808_mos': 'DNSMOS'})\n",
    "    pivot = pivot.join(meta_lookup[['label']], how='left')\n",
    "    pivot = pivot[['label', 'PESQ', 'STOI', 'SI_SDR', 'DNSMOS']]\n",
    "    return pivot.sort_values('DNSMOS', ascending=False)\n",
    "\n",
    "pct_vs_noise = compute_percentage_gain('BASELINE_NOIZEUS_EARS')\n",
    "pct_vs_gtcrn = compute_percentage_gain('GTCRN_EXP3p2a')\n",
    "\n",
    "display(pct_vs_noise)\n",
    "display(pct_vs_gtcrn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9e8c65",
   "metadata": {},
   "source": [
    "## Best Configuration per Metric and SNR\n",
    "Identifies which setup delivers the highest score for each metric at each SNR level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c73044",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_records = []\n",
    "for snr in snr_levels:\n",
    "    subset = summary_by_snr[summary_by_snr['SNR'] == snr]\n",
    "    for metric in metrics_of_interest:\n",
    "        idx = subset[metric].idxmax()\n",
    "        row = subset.loc[idx]\n",
    "        best_records.append({\n",
    "            'SNR': snr,\n",
    "            'Metric': metric,\n",
    "            'Best Config': row['label'],\n",
    "            'Score': row[metric],\n",
    "        })\n",
    "best_table = pd.DataFrame(best_records)\n",
    "best_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a4653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_display = {\n",
    "    \"PESQ\": \"PESQ\",\n",
    "    \"STOI\": \"STOI\",\n",
    "    \"SI_SDR\": \"SI-SDR\",\n",
    "    \"DNSMOS_p808_mos\": \"DNSMOS\",\n",
    "}\n",
    "\n",
    "label_lookup = {key: meta.get(\"label\", key) for key, meta in catalog.items()}\n",
    "\n",
    "def best_by_snr_with_gain(reference_key: str) -> pd.DataFrame:\n",
    "    \"\"\"Return best-performing configuration per SNR/metric with percent gain vs reference.\"\"\"\n",
    "    reference_slice = (\n",
    "        summary_by_snr[summary_by_snr[\"experiment\"] == reference_key]\n",
    "        .set_index(\"SNR\")\n",
    "    )\n",
    "    rows = []\n",
    "    for snr in snr_levels:\n",
    "        snr_slice = summary_by_snr[summary_by_snr[\"SNR\"] == snr]\n",
    "        if snr_slice.empty:\n",
    "            continue\n",
    "        for metric in metrics_of_interest:\n",
    "            best_idx = snr_slice[metric].idxmax()\n",
    "            best_row = snr_slice.loc[best_idx]\n",
    "            ref_value = reference_slice.loc[snr, metric] if snr in reference_slice.index else np.nan\n",
    "            pct_gain = np.nan\n",
    "            if pd.notnull(ref_value) and ref_value != 0:\n",
    "                pct_gain = ((best_row[metric] - ref_value) / ref_value) * 100\n",
    "            rows.append({\n",
    "                \"SNR (dB)\": snr,\n",
    "                \"Metric\": metric_display.get(metric, metric),\n",
    "                \"Best Config\": label_lookup.get(best_row[\"experiment\"], best_row[\"experiment\"]),\n",
    "                \"Score\": best_row[metric],\n",
    "                \"Reference\": label_lookup.get(reference_key, reference_key),\n",
    "                \"Ref Score\": ref_value,\n",
    "                \"Pct Gain (%)\": pct_gain,\n",
    "            })\n",
    "    result = pd.DataFrame(rows)\n",
    "    return result.sort_values([\"SNR (dB)\", \"Metric\"])\n",
    "\n",
    "best_vs_noisy = best_by_snr_with_gain(\"BASELINE_NOIZEUS_EARS\")\n",
    "best_vs_gtcrn = best_by_snr_with_gain(\"GTCRN_EXP3p2a\")\n",
    "\n",
    "display(best_vs_noisy.round({\"Score\": 3, \"Ref Score\": 3, \"Pct Gain (%)\": 1}))\n",
    "display(best_vs_gtcrn.round({\"Score\": 3, \"Ref Score\": 3, \"Pct Gain (%)\": 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6fc96a",
   "metadata": {},
   "source": [
    "## Metric Trends vs SNR\n",
    "Visualize how GTCRN compares against the Wiener variants across SNR for each objective metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f084815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an explicit color mapping so each label gets a consistent, unique color\n",
    "label_order = [catalog[key]['label'] for key in catalog]\n",
    "label_map = {key: meta['label'] for key, meta in catalog.items()}\n",
    "palette_colors = sns.color_palette(\"tab20\", n_colors=len(label_order))\n",
    "palette = {label: color for label, color in zip(label_order, palette_colors)}\n",
    "marker_map = {label: ('X' if label == 'GTCRN (No WF)' else 'o') for label in label_order}\n",
    "plot_df = summary_by_snr.copy()\n",
    "plot_df['label'] = plot_df['experiment'].map(label_map)\n",
    "# Optionally ensure labels present in the data preserve the requested order\n",
    "plot_df['label'] = pd.Categorical(plot_df['label'], categories=label_order, ordered=True)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10), sharex=True)\n",
    "axes = axes.flatten()\n",
    "for idx, metric in enumerate(metrics_of_interest):\n",
    "    ax = axes[idx]\n",
    "    sns.lineplot(\n",
    "        data=plot_df,\n",
    "        x='SNR',\n",
    "        y=metric,\n",
    "        hue='label',\n",
    "        style='label',\n",
    "        markers=marker_map,\n",
    "        dashes=False,\n",
    "        palette=palette,\n",
    "        hue_order=label_order,\n",
    "        style_order=label_order,\n",
    "        ax=ax,\n",
    "        linewidth=2.0,\n",
    "    )\n",
    "    ax.set_title(metric)\n",
    "    ax.set_xlabel('SNR (dB)')\n",
    "    ax.legend().remove()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.88])\n",
    "fig.legend(\n",
    "    handles,\n",
    "    labels,\n",
    "    loc='upper center',\n",
    "    ncol=4,\n",
    "    frameon=False,\n",
    "    bbox_to_anchor=(0.5, 0.99),\n",
    ")\n",
    "plot_path = figures_dir / \"gtcrnwf_metric_trends.png\"\n",
    "fig.savefig(plot_path, bbox_inches='tight')\n",
    "plot_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8df746",
   "metadata": {},
   "source": [
    "## DNSMOS per SNR for Key Systems\n",
    "We compare the overall DNSMOS across SNR levels for the standalone GTCRN, the standalone 25 ms Wiener filter default configuration, and the combined GTCRN+WF (25 ms, $\\mu=0.98$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_keys = [\n",
    "    \"GTCRN_EXP3p2a\",\n",
    "    \"WF_EXP1p1d\",\n",
    "    \"GTCRNWF_EXP3p2a_25ms_quality\",\n",
    "]\n",
    "bar_metric = \"DNSMOS_p808_mos\"\n",
    "bar_df = summary_by_snr[summary_by_snr[\"experiment\"].isin(selected_keys)].copy()\n",
    "bar_df[\"label\"] = bar_df[\"experiment\"].map(label_map)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    data=bar_df,\n",
    "    x=\"SNR\",\n",
    "    y=bar_metric,\n",
    "    hue=\"label\",\n",
    "    order=snr_levels,\n",
    "    ax=ax,\n",
    "    palette=\"Set2\",\n",
    ")\n",
    "ax.set_xlabel(\"SNR (dB)\")\n",
    "ax.set_ylabel(\"DNSMOS (Overall)\")\n",
    "ax.set_title(\"DNSMOS vs SNR for GTCRN and Wiener Variants\")\n",
    "ax.legend(title=\"System\", loc=\"best\")\n",
    "ax.grid(True, axis=\"y\", alpha=0.3)\n",
    "fig.tight_layout()\n",
    "bars_path = figures_dir / \"gtcrnwf_25ms_dnsmos_bars.png\"\n",
    "fig.savefig(bars_path, bbox_inches=\"tight\")\n",
    "bars_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a0d326",
   "metadata": {},
   "source": [
    "## Noise-Type Breakdown\n",
    "Replicates the per-noise analysis from earlier experiments by averaging each metric per noise class and SNR for every configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d33d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_breakdown = (\n",
    "    full_results.dropna(subset=[\"noise_type\"])\n",
    "    .groupby([\"noise_type\", \"SNR\", \"experiment\"], as_index=False)[metrics_of_interest]\n",
    "    .mean()\n",
    ")\n",
    "noise_breakdown[\"label\"] = noise_breakdown[\"experiment\"].map(label_map)\n",
    "noise_breakdown = noise_breakdown.sort_values([\"noise_type\", \"SNR\", \"label\"])\n",
    "noise_label_order = [label for label in label_order if label in noise_breakdown[\"label\"].unique()]\n",
    "display(noise_breakdown.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b232ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_noise_type_breakdown(\n",
    "    data: pd.DataFrame,\n",
    "    metrics: List[str],\n",
    "    snr_levels: List[int],\n",
    "    label_order: List[str],\n",
    "    save_dir: Optional[Path] = None,\n",
    " ) -> None:\n",
    "    \"\"\"Visualize metric trends per noise type and SNR for each configuration.\"\"\"\n",
    "    for metric in metrics:\n",
    "        for snr in snr_levels:\n",
    "            subset = data[data[\"SNR\"] == snr]\n",
    "            if subset.empty:\n",
    "                continue\n",
    "            fig, ax = plt.subplots(figsize=(14, 7))\n",
    "            sns.pointplot(\n",
    "                data=subset,\n",
    "                x=\"noise_type\",\n",
    "                y=metric,\n",
    "                hue=\"label\",\n",
    "                hue_order=label_order,\n",
    "                palette=\"tab10\",\n",
    "                dodge=0.3,\n",
    "                markers=\"o\",\n",
    "                linestyles=\"-\",\n",
    "                errorbar=None,\n",
    "                ax=ax,\n",
    "            )\n",
    "            ax.set_title(f\"{metric} by Noise Type at {snr} dB\", fontweight=\"bold\", pad=14)\n",
    "            ax.set_xlabel(\"Noise Type\", fontweight=\"bold\")\n",
    "            ax.set_ylabel(metric, fontweight=\"bold\")\n",
    "            ax.tick_params(axis=\"x\", labelrotation=90)\n",
    "            plt.setp(ax.get_xticklabels(), ha=\"center\")\n",
    "            ax.grid(True, axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "            ax.legend(title=\"System\", bbox_to_anchor=(1.02, 1), loc=\"upper left\", frameon=True)\n",
    "            plt.tight_layout()\n",
    "            if save_dir is not None:\n",
    "                save_dir.mkdir(parents=True, exist_ok=True)\n",
    "                fig_path = save_dir / f\"{metric}_noise_breakdown_{snr}dB.png\"\n",
    "                fig.savefig(fig_path, bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "    print(f\"Generated {len(metrics)} Ã— {len(snr_levels)} noise-type plots.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e00d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_by_noise_type_with_gain(reference_key: str) -> pd.DataFrame:\n",
    "    \"\"\"Return best-performing configuration per noise type, SNR, and metric with % gain.\"\"\"\n",
    "    reference_slice = (\n",
    "        noise_breakdown[noise_breakdown[\"experiment\"] == reference_key]\n",
    "        .set_index([\"noise_type\", \"SNR\"])\n",
    ")\n",
    "    rows = []\n",
    "    for noise, snr in noise_breakdown[[\"noise_type\", \"SNR\"]].drop_duplicates().itertuples(index=False):\n",
    "        noise_slice = noise_breakdown[(noise_breakdown[\"noise_type\"] == noise) & (noise_breakdown[\"SNR\"] == snr)]\n",
    "        if noise_slice.empty:\n",
    "            continue\n",
    "        for metric in metrics_of_interest:\n",
    "            best_idx = noise_slice[metric].idxmax()\n",
    "            best_row = noise_slice.loc[best_idx]\n",
    "            ref_value = np.nan\n",
    "            if (noise, snr) in reference_slice.index:\n",
    "                ref_value = reference_slice.loc[(noise, snr), metric]\n",
    "            pct_gain = np.nan\n",
    "            if pd.notnull(ref_value) and ref_value != 0:\n",
    "                pct_gain = ((best_row[metric] - ref_value) / ref_value) * 100\n",
    "            rows.append({\n",
    "                \"Noise Type\": noise,\n",
    "                \"SNR (dB)\": snr,\n",
    "                \"Metric\": metric_display.get(metric, metric),\n",
    "                \"Best Config\": label_lookup.get(best_row[\"experiment\"], best_row[\"experiment\"]),\n",
    "                \"Score\": best_row[metric],\n",
    "                \"Reference\": label_lookup.get(reference_key, reference_key),\n",
    "                \"Ref Score\": ref_value,\n",
    "                \"Pct Gain (%)\": pct_gain,\n",
    "            })\n",
    "    result = pd.DataFrame(rows)\n",
    "    return result.sort_values([\"Noise Type\", \"SNR (dB)\", \"Metric\"])\n",
    "\n",
    "best_noise_vs_noisy = best_by_noise_type_with_gain(\"BASELINE_NOIZEUS_EARS\")\n",
    "best_noise_vs_gtcrn = best_by_noise_type_with_gain(\"GTCRN_EXP3p2a\")\n",
    "\n",
    "display(best_noise_vs_noisy.round({\"Score\": 3, \"Ref Score\": 3, \"Pct Gain (%)\": 1}))\n",
    "display(best_noise_vs_gtcrn.round({\"Score\": 3, \"Ref Score\": 3, \"Pct Gain (%)\": 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2012ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_breakdown_dir = figures_dir / \"noise_type_breakdown\"\n",
    "plot_noise_type_breakdown(\n",
    "    data=noise_breakdown,\n",
    "    metrics=metrics_of_interest,\n",
    "    snr_levels=snr_levels,\n",
    "    label_order=noise_label_order,\n",
    "    save_dir=noise_breakdown_dir,\n",
    " )\n",
    "noise_breakdown_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd305ca2",
   "metadata": {},
   "source": [
    "## Focused Comparison: GTCRN vs 25 ms Wiener Variants\n",
    "Focused look at WF 25 ms default, GTCRN alone, and GTCRN+WF 25 ms ($\\mu=0.98$) to report best-performer tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f748a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_experiments = [\n",
    "    \"WF_EXP1p1d\",\n",
    "    \"GTCRN_EXP3p2a\",\n",
    "    \"GTCRNWF_EXP3p2a_25ms_quality\",\n",
    "]\n",
    "focused_summary = summary_by_snr[summary_by_snr[\"experiment\"].isin(focused_experiments)].copy()\n",
    "focused_noise = noise_breakdown[noise_breakdown[\"experiment\"].isin(focused_experiments)].copy()\n",
    "\n",
    "def best_within_subset_by_snr(data: pd.DataFrame, reference_key: str) -> pd.DataFrame:\n",
    "    reference_slice = data[data[\"experiment\"] == reference_key].set_index(\"SNR\")\n",
    "    rows = []\n",
    "    for snr in snr_levels:\n",
    "        snr_slice = data[data[\"SNR\"] == snr]\n",
    "        if snr_slice.empty:\n",
    "            continue\n",
    "        for metric in metrics_of_interest:\n",
    "            best_idx = snr_slice[metric].idxmax()\n",
    "            best_row = snr_slice.loc[best_idx]\n",
    "            ref_value = reference_slice.loc[snr, metric] if snr in reference_slice.index else np.nan\n",
    "            pct_gain = np.nan\n",
    "            if pd.notnull(ref_value) and ref_value != 0:\n",
    "                pct_gain = ((best_row[metric] - ref_value) / ref_value) * 100\n",
    "            rows.append({\n",
    "                \"SNR (dB)\": snr,\n",
    "                \"Metric\": metric_display.get(metric, metric),\n",
    "                \"Best Config\": label_lookup.get(best_row[\"experiment\"], best_row[\"experiment\"]),\n",
    "                \"Score\": best_row[metric],\n",
    "                \"Reference\": label_lookup.get(reference_key, reference_key),\n",
    "                \"Ref Score\": ref_value,\n",
    "                \"Pct Gain (%)\": pct_gain,\n",
    "            })\n",
    "    result = pd.DataFrame(rows)\n",
    "    return result.sort_values([\"SNR (dB)\", \"Metric\"])\n",
    "\n",
    "def best_within_subset_by_noise(data: pd.DataFrame, reference_key: str) -> pd.DataFrame:\n",
    "    reference_slice = data[data[\"experiment\"] == reference_key].set_index([\"noise_type\", \"SNR\"])\n",
    "    rows = []\n",
    "    for noise, snr in data[[\"noise_type\", \"SNR\"]].drop_duplicates().itertuples(index=False):\n",
    "        noise_slice = data[(data[\"noise_type\"] == noise) & (data[\"SNR\"] == snr)]\n",
    "        if noise_slice.empty:\n",
    "            continue\n",
    "        for metric in metrics_of_interest:\n",
    "            best_idx = noise_slice[metric].idxmax()\n",
    "            best_row = noise_slice.loc[best_idx]\n",
    "            ref_value = np.nan\n",
    "            if (noise, snr) in reference_slice.index:\n",
    "                ref_value = reference_slice.loc[(noise, snr), metric]\n",
    "            pct_gain = np.nan\n",
    "            if pd.notnull(ref_value) and ref_value != 0:\n",
    "                pct_gain = ((best_row[metric] - ref_value) / ref_value) * 100\n",
    "            rows.append({\n",
    "                \"Noise Type\": noise,\n",
    "                \"SNR (dB)\": snr,\n",
    "                \"Metric\": metric_display.get(metric, metric),\n",
    "                \"Best Config\": label_lookup.get(best_row[\"experiment\"], best_row[\"experiment\"]),\n",
    "                \"Score\": best_row[metric],\n",
    "                \"Reference\": label_lookup.get(reference_key, reference_key),\n",
    "                \"Ref Score\": ref_value,\n",
    "                \"Pct Gain (%)\": pct_gain,\n",
    "            })\n",
    "    result = pd.DataFrame(rows)\n",
    "    return result.sort_values([\"Noise Type\", \"SNR (dB)\", \"Metric\"])\n",
    "\n",
    "focused_best_vs_gtcrn = best_within_subset_by_snr(focused_summary, \"GTCRN_EXP3p2a\")\n",
    "focused_noise_best_vs_gtcrn = best_within_subset_by_noise(focused_noise, \"GTCRN_EXP3p2a\")\n",
    "\n",
    "display(focused_best_vs_gtcrn.round({\"Score\": 3, \"Ref Score\": 3, \"Pct Gain (%)\": 1}))\n",
    "display(focused_noise_best_vs_gtcrn.round({\"Score\": 3, \"Ref Score\": 3, \"Pct Gain (%)\": 1}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
